<!-- image -->

## Managing the Information Systems Infrastructure and Services

Preview

Just  as  any  city  depends  on  a  functioning  infrastructure, companies operating in the digital world are relying on a comprehensive  information  systems  (IS)  infrastructure  to support their business processes and competitive strategy. Transactions are conducted with ever-increasing speed; likewise, with ever-increasing amounts of data to be captured, analyzed, and stored, companies must thoroughly plan and manage their infrastructure needs to gain the greatest returns on their IS investments. When planning and managing their IS architectures, organizations must answer many important and difficult questions. For example, how will we utilize information systems to enable our competitive strategy? What technologies and systems best support our core business processes? Which vendors should we partner with, which technologies do we adopt, and which do we avoid? What hardware, software, or services do we buy, build, or have managed by an outside service provider? How can we use cloud computing to increase our agility? Clearly, effectively managing an organization' s IS infrastructure is a complex but necessary activity in today' s digital world.

This chapter focuses on helping managers understand the key components of a comprehensive IS infrastructure and why its careful management is necessary. With the increasing complexity of an organization' s information needs and the increasing complexity of the systems needed to satisfy these requirements, the topic of infrastructure management is fundamental for managing in the digital world.

## MANAGING IN THE DIGITAL WORLD:

## From Google to Alphabet

N early everyone in the entire world knows a few global brands such as Apple, Coca-Cola, Samsung, and Toyota. Another powerful brand, Google, has become known around the world for its ubiquitous search engine (Figure 3.1). But Google is much more than a search engine. Google has very diverse interests, from driverless cars  and  other  technologies  to  life  sciences,  investment capital,  and  space  exploration  through  investments  in SpaceX. Given this diversity, many things that Google was exploring didn't fall neatly under a search engine company, not to mention spending billions of dollars on many 'blue ocean' R&amp;D projects that were not always viewed favorably by investors. To make the point that Google is interested  in  far  more  than  search  engines  and  to  help sharpen the focus of the various Google-owned companies, a holding company called Alphabet was created. This giant  restructuring  of  the  Google  empire  has  placed  13 companies under the Alphabet umbrella (in early 2020) and allows Alphabet to have different types of companies, allowing investors the choice of investing in Alphabet or in one of the subsidiary companies that are publicly traded.

With this move to Alphabet, it has become much easier for investors to understand the Google business model and how each of the various companies (often referred to  as  'Other  Bets')  are  contributing  to  (or  harming) Alphabet's bottom line. For example, Alphabet owns the artificial  intelligence  business  DeepMind,  life  sciences

After reading this chapter, you will be able to do the following:

1.  Describe how changes in businesses' competitive landscape influence changing IS infrastructure needs.
2.  Describe the essential components of an organization's IS infrastructure.
3.  Discuss managerial issues associated with managing an organization's IS infrastructure.
4.  Describe cloud computing and other current trends that can help an organization address IS infrastructure-related challenges.

<!-- image -->

brand; the intention is for the various Alphabet companies to be independent and develop their own brands and innovations. This way, the likelihood of finding the next new idea that can change the world is much higher.

## FIGURE 3.1

Google search page.

Source: Google and the Google logo are registered trademarks of Google LLC, used with permission.

company  Verily,  and  autonomous  driving  company Waymo.  With  the  restructuring,  financial  reporting shows where revenue is generated and where investments in new ideas are made. Investors are thrilled with this new transparency, and many feel that Alphabet will be  more  disciplined  about  where  it  will  place  investment bets as successes and failures will be more visible and tightly associated with a particular company.

Alphabet is now one of the biggest companies in the world. For most of us who use Gmail and Google Docs or watch countless YouTube videos, the shift to Alphabet won't even be noticeable. However, for those in the business and technology world, they better take notice! Google's founders Sergey Brin and Larry Page don't want to relax as simply the giants of online search; they have 'always  strived  to  do  more,  and  to  do  important  and meaningful things with the resources [they] have' (Page, 2015)  Alphabet  is  not  intended  to  be  a  big  consumer

Brin and Page believe that large companies get comfortable  with  their  success  and  business  model.  Both want to continue to innovate and create inventions that can transform the world. For now, Google's search engine is bringing in most of the revenue and is highly profitable. But these tech pioneers are looking toward the future, aiming to take a long-term view and 'improving the lives of as many people as [they] can' (Google, n.d.).

Clearly, Alphabet is about more than search engines, and its founders are about more than resting on prior accomplishments.

After reading this chapter, you will be able to answer the following:

1. How does Google benefit from a well-functioning infrastructure?
2. What are the major components of Google's infrastructure?
3. What are the factors organizations should consider when building on infrastructure provided by Google?

Based on:

Google. (n.d.). Commitments. Google. Retrieved April 19, 2020, from https://about.google/commitments

Google. (n.d.). From the garage to the Googleplex. Google. Retrieved June 10, 2020, from https://about.google/our-story

Hartmans, A. and Meisenzahl, M. (2020, February 12). All the companies and divisions under Google's parent company, Alphabet, which just made yet another shake-up to its structure. Business Insider. Retrieved June 10, 2020, from https://www.businessinsider.com/ alphabet-google-company-list-2017-4

Page, L. (2015). G is for Google. abc.xyz . Retrieved June 10, 2020, from https://abc.xyz/investor/founders-letters/2015

## FIGURE 3.2

Infrastructure components of a city enable the provision of basic services.

Source: Edin Ramic/Shutterstock.

## The IS Infrastructure

Most people expect a variety of basic municipal services, such as sanitation, security, transportation, provision of energy and water, and so on, to be provided by the city they live in. Any area where people live or work needs a supporting infrastructure , which entails the technical structures enabling the provision of services (Figure 3.2); many infrastructure components, such as power, telephone, water, and sewage lines, are 'invisible' to the users, meaning that the users typically do not know (or even care) where, for example, their water comes from, as long as it flows when they open their faucets. Other, more visible, infrastructure  components  include  streets, schools, hospitals, and parks. Both the area's inhabitants and businesses depend on the services provided by that infrastructure, and cities with a good infrastructure are considered more livable than cities with poorer infrastructure and are much more likely to attract businesses and residents.

For organizations, many decisions are based on the provision of such services, such as when choosing a site for a new manufacturing plant or company headquarters. Indeed, many municipalities attempt to attract new businesses and industries by setting up new commercial zones with a well-planned infrastructure. In some cases, specific infrastructure components are of special importance, such as access to freeways or rail tracks or sufficient availability of cheap energy. Just as an aluminum smelter needs access to rail tracks or an ample supply of energy, the data centers powering much of the digital world need connectivity to the internet backbone (i.e., the collection of primary network connections and telecommunications lines making up the internet) and energy for powering and cooling the computers. With rising costs of energy, companies such as Google, Apple, and Facebook are not only looking for technological advances to increase the efficiency of their data centers but also trying to find geographical locations where energy efficiency can be optimized. One such example is search engine giant Google, which built a data center in an abandoned paper mill in Hamina, Finland, where the cool climate reduced the need for cooling (Figure 3.3). This location also provided the necessary connectivity and allowed for using seawater for cooling. Likewise, Apple and Facebook built data centers in the high desert in Oregon, where power is cheap and the cool climate significantly reduces the need for cooling.

For organizations operating globally, local differences in infrastructure pose additional challenges, particularly when operating in developing nations. For example, in many parts of the world, organizations cannot count on an uninterrupted supply of water or electricity.

<!-- image -->

<!-- image -->

Consequently, many of the large call centers in India that support customers around the world for companies like Dell Computers or Citibank have installed massive power generators to minimize the effects of frequent power outages or have set up their own satellite links to be independent from the local, unreliable communications networks.

Just as people and companies rely on basic municipal services to function, businesses rely on an information systems infrastructure (also referred to as digital infrastructure ) (consisting of hardware, system software, storage, networking, and data centers) to support analytics and decision making, business processes, and competitive strategy. No matter what systems are used for, they rely on three basic capabilities supported by the information systems infrastructure: processing, storage, and transmission of data (Figure 3.4).

Organizations nowadays are facing continuously changing business environments. Traditionally, companies were operating in relatively stable markets and could gain or sustain competitive advantage from relatively few innovations. Advances in information and communication technologies have leveled the playing field, allowing even small companies from all over the world to compete on a global scale. As new competitors can literally come out of nowhere, any competitive advantage will be increasingly short-lived, forcing organizations to keep innovating.

This suggests that digital infrastructures can have a profound influence on not only businesses but also individuals and society in at least three important ways. First, over time, new systems and capabilities are built on top of prior systems, acting to refine and extend the capabilities of prior generations of systems in ways much easier than physical infrastructure like roads and electrical grids, which are much more difficult to fundamentally change. This acts to accelerate innovation and change in ways never before possible. Second, again in contrast to other types of traditional infrastructure components, digital infrastructures are typically not controlled by a single business or government actor but are provided by companies such as Amazon, Google, and Rackspace. In other words, there is a competitive and market-based environment that acts to accelerate innovation and change. Third, digital infrastructures allow for platformbased business models that permeate almost every aspect of our daily lives, from having your Fitbit monitor your sleep and waking you in the morning, to making a Skype call with a friend on another continent, to working on your homework on the train, to commenting on an image on Instagram in the evening. All day, everywhere, digital infrastructures are a key part of your life, whether you are a student, working full time, or retired. Given this pervasiveness, new digital ventures are leveraging these infrastructures to innovate and create value for customers. Likewise, with all this change and innovation, governments struggle to introduce policies that can enable adequate security and privacy without stifling innovation.

## FIGURE 3.3

Google built a data center in an abandoned paper mill in Hamina, Finland.

Source: Maykova Galina/Shutterstock.

## FIGURE   3.  4

The information systems infrastructure enables processing, storing, and transmission of data.

<!-- image -->

<!-- image -->

## DIGITAL DENSITY

## Contact Tracing

A hotspot is a place of significance-whether it be a place for commerce or a place that is popular for dining and dancing. When we think about mobile technology and hotspots, we tend to think of busy places with free public access to Wi-Fi. Such Wi-Fi hotspots are often located where people gather, such as airports, train stations, libraries, convention centers, coffee shops, and hotels. Because such hotspots are often used by a large and dynamic number of people, researchers can use them to study a broad range of topics ranging from crowd movements to fashion and entertainment trends. To aid in this work, researchers have also created algorithms for estimating the number of people in a room that cannot be seen or even the number of people in a large crowd by analyzing the number of smartphone devices with their Wi-Fi antenna turned on within a given area. In the united States and in much of the developed world, there are lots of restrictions related to cell phone tracking due to numerous privacy concerns, but there are currently no laws restricting the tracking of devices connected to Wi-Fi (especially when a user agrees to the terms required to use a free Wi-Fi hotspot). While using such techniques to estimate the number of people cannot lead to a perfect measure-as researchers have to make assumptions about the number of people without devices, the number of devices with Wi-Fi turned off, and even those with more than one device-it allows for a pretty good estimate. With a good estimate of the total number of people, and with a good estimate on the physical location of each individual, forecasts of various things can be made based on random sampling and knowing the population size.

So, what does Wi-Fi have to do with CovId-19 and contact tracing? The onset of the CovId-19 pandemic brought many uncertainties for citizens of countries around the world. not only is the disease highly infectious, it is also mortally dangerous, especially for individuals of certain age groups or with preexisting health conditions that compromise their ability to fight off infection. Although it is nearly impossible to stop the spread of the virus, it is possible to control and estimate the extent of the spread through contact tracing. Wi-Fi and other communication networks such as Bluetooth give researchers and health organizations the ability to estimate where and when an individual traveled, and who they might have come into contact with during those travels. For example, consider a situation where you have not previously been exposed to CovId-19 and you made a trip to the market on Monday at 8:35 AM. obviously, the market is a public place and other individuals would have also traveled there at the same time. With that in mind, imagine a couple of days later another individual that was in the same physical area of the market as you at roughly the same time tested positive for CovId-19. Through contact tracing technology, that individual could inform the network of users that a positive case was recorded. you would then receive a notification that you may have been exposed to the virus (at the market on Monday at 8:35 AM), and accordingly, you should minimize your risk of exposing others until you know through testing that you did not contract the virus.

Clearly the data collected and connections identified between individuals is powerfully important for public health during a pandemic. However, consider the privacy concerns that arise from such a situation. In many countries around the world, individual privacy protections are required by law, and health data is no exception. Therefore, the challenge becomes how do we, in a technology-enabled society, derive positive benefits for public health through contact tracing, while at the same time protect the privacy of the individuals that are part of the network? While the tracking of individuals raises many privacy concerns, using data mining, advanced analytics, and privacy enabling features is allowing researchers to better combat the spread of disease; as is typical in the digital world, many advances come with equally troubling concerns.

Based on:

Holger, d. (2018, november 1). How 'free' Wi-Fi hotspots can track your location even when you aren't connected. PCWorld. Retrieved  June  15,  2020,  from  https://www.pcworld.com/ article/3315197/free-wi-fi-hotspots-can-track-your-location-evenwhen-you-arent-connected.html

Knight, W. (2020, March 15). Phones could track the spread of CovId19. Is it a good idea? Wired. Retrieved June 15, 2020, from https:// www.wired.com/story/phones-track-spread-covid19-good-idea

Facing this accelerating change enabled by digital infrastructures, organizations must adapt or will sooner or later go out of business. Quickly adapting to a constantly changing competitive environment necessitates that businesses are increasingly flexible and agile. To achieve this flexibility and agility, organizations seek to align their organizational strategy and business processes with the right collection of systems and capabilities in the IS infrastructure. The formal description of an organization's technologies, systems, and processes that support an organization's specific business processes and strategy is referred to as the information systems architecture . In other words, the IS infrastructure provides a broad and flexible set of capabilities that can be utilized in a variety of ways. The IS architecture describes how the specific capabilities from this overarching set of capabilities are designed to support the specific strategy and processes of an organization. As discussed in Chapter 2, 'Gaining Competitive Advantage Through Information Systems,' business-IT alignment is a continuous process of adjusting business goals and the IS architecture to achieve business objectives (Figure 3.5). To achieve alignment, changing business conditions drive a refinement of the organization's IS architecture, which necessitates changes in what IS infrastructure components and capabilities are implemented or utilized. Likewise, innovative business models and processes and associated refinements to the IS architecture result in changes and enhancements in the IS infrastructure. In addition, any lack of availability, performance, or security (e.g., the news of an organization's website being attacked by hackers or collapsing under unanticipated customer demand) is often immediately visible to customers or other stakeholders, potentially leading to loss of business, trust, and goodwill. Thus, organizations' business processes need to be supported by the right applications and the right data, which in turn rely on a robust and evolving IS infrastructure   (Figure 3.6). In sum, organizations rely on a complex, interrelated IS infrastructure to thrive in the everincreasingly competitive digital world.

To get a better understanding of an IS infrastructure, we first provide a brief overview of how applications and databases support business processes and then discuss how hardware, system software, storage, networking, and data centers interact to form an organization's IS infrastructure. Note that in this chapter, we will primarily focus on these components from a business perspective. For more technical details, please refer to the Technology Briefing.

## Applications and Databases Supporting Business Processes

Data are probably among the most important assets an organization has, as data are essential for both executing business processes and gaining business intelligence through advanced analytics.

<!-- image -->

## FIGURE 3.5

Business-IT alignment drives IS infrastructure changes to enable innovative business models and processes.

## FIGURE 3.6

A robust and evolving IS infrastructure is needed to support an organization's strategy and business processes.

<!-- image -->

Infrastructure Hardware System Software Storage Networking Data Centers

No matter what the business process is, data are used, processed, or generated along the way. For example, business processes associated with manufacturing products require data about inventory levels of raw materials, production capacities, and demand forecasts; likewise, back-office business processes associated with accounts receivable require data about customers, sales, receipts, and so on. In addition, especially in light of ever-increasing digital density, increasing amounts of data are available to be analyzed for increased personalization, coordination, or anticipation of changes. Data once taken for granted or never collected at all are now used to make organizations more productive and competitive. Stock prices in the market, potential customers who meet a company's criteria for its products' target audiences, users' locations, weather data, or the operating status of manufacturing machines are just some of the types of data that organizations collect and analyze to turn into useful information. Yet just having access to data is not sufficient; it is through applications that the data can be used effectively. Next, we briefly describe the role of application software in supporting an organization's business processes.

APPLICATION SOFTWARE. Organizations are continuously looking for ways to streamline and automate business processes to generate more revenue or reduce costs and make the organization more profitable. Application software helps automate business processes and enables processes that would otherwise not even be possible. Accountants have, for centuries, used thick books for maintaining the accounting records of a business; automating the associated tasks using accounting software applications not only has helped to make the tasks less effortful and reduce error rates but, in addition, allows quick analysis of accounting records to examine sales trends, delinquencies, profit margins, and the like. Similarly, automating inventory management functions using specialized inventory management software not only helps keep a more accurate and up-to-date inventory but can also generate a wealth of data that can be used to optimize inventory levels, taking into account the costs of keeping inventory and the potential costs of stockouts. E-commerce websites such as Amazon would not be possible without the applications needed for automatically processing transactions.

In addition to various types of application software for different business functions, other types of application software let users perform tasks such as writing business letters, managing stock portfolios, or manipulating forecasts to come up with the most efficient allocation of resources for a project. Application software also includes personal productivity software such as Microsoft Office; supply chain management systems to support the coordination of suppliers as well as the production and distribution of products or services; or customer relationship management (CRM) systems to help companies win and retain customers, gain marketing and customer insights, and focus on customer service (as discussed in Chapter 1, 'Managing in the Digital World').

Many types of application software supporting business processes interact with databases, which allow them to efficiently retrieve and store the data needed for executing business processes and gaining business intelligence. Databases are discussed next.

DATABASES. Databases , which are collections of related data organized in a way that facilitates data searches, are vital to an organization's operations and often are vital to competitive advantage and success. In organizations, databases are performing various important functions.

<!-- image -->

## ETHICAL DILEMMA

## Putting People's Lives Online

Is that a man breaking into an apartment? There's obviously a house on fire. The lady in this picture looks exactly like my next-door neighbor, and those are obviously my clothes drying in my backyard. Search a random location on Google Maps, and you may find-via the Street view feature-the most unexpected candid shots of people walking on the street, waiting for a bus, or even hanging out in places they may not want others to know about. Without doubt, Google Maps can be tremendously useful; combining traditional maps, information from the web, and innovative technology, the application is a helpful assistant for planning trips, locating businesses, and so on. However, Google Maps has been under fire since the introduction of the Street view feature, with many questioning whether a strict line has been unnecessarily crossed in the invasion of public privacy.

conceded that it violated privacy when it scooped up passwords, email, and other personal information from unsuspecting computers as it drove through cities and neighborhoods.

The issues surrounding Google's Street view highlight an even broader issue: With ever more (often very personal) data being stored, shared, and exchanged in the cloud, companies such as Google, Facebook, and Apple effectively become the custodians of data that have the potential to ruin the lives of an untold number of people. Having access to vast amounts of data provides the potential of monetizing the data in some way.

## Questions

The biggest argument behind the dilemma is the collective sense of intrusion that has stimulated concerns of losing one's privacy-parents are worried pictures of their children could possibly make them targets of child predators, and people visiting adult shops simply do not find it essential for the entire world to know where they went last Saturday afternoon. Although Google has, so far, attempted to ease public concern by blurring the faces of people, license plate numbers, and house numbers, it still is rather awkward to find, say, a good shot of your underclothes hanging on the clothesline and be informed about it by another person. The way Street view operates indeed creates a sense of insecurity; many critics erroneously believe that Street view resembles having a gigantic security camera capturing their every move without their consent  or  further,  even  without  their  being  aware  of  it. Additionally, when collecting pictures for Street view, Google

1. Are the laws governing how Facebook, Google, and other companies handle their customers' online data effective? What should be the penalties of misuse?
2. How can a company balance the responsibility that comes with having access to the data with the responsibility toward the company's shareholders to maximize profits?

Based on:

Anonymous. (2020). Google-contributed street view imagery policy. Google Maps . Retrieved June 10, 2020, from https://www.google .com/streetview/policy duffy, C. (2019, July 25) Google agrees to pay $13 million in Street view privacy case. CNN Business. Retrieved June 10, 2020, from https://www.cnn.com/2019/07/22/tech/google-street-view-privacylawsuit-settlement/index.html

Mallinson, H. (2020, April 16). Google Maps Street view's ridiculous privacy blunder captured in very funny photo. Daily Express. Retrieved June 10, 2020, from https://www.express.co.uk/travel/ articles/1269982/google-maps-street-view-privacy-cow-cambridgeface-blurring-funny-photo

On the most fundamental level, databases are used to store data and to make the data accessible where and when needed. More specifically, the use of databases to store organizational data ranging from inventory to demand forecasts to customer data enables applications from across an organization to access the data needed. Typically, various business processes throughout an organization make use of the same data, and providing the associated applications with quick and easy access to the data can help streamline and optimize these processes. For example, if a salesperson has access to inventory levels, she can quickly give precise estimates of delivery times, which may help close the sale. Similarly, if business processes associated with inbound logistics or operations have access to order forecasts, this can help to streamline procurement and production processes, helping to avoid stockouts and minimize money tied up in excess inventory. Likewise, the use of databases enables the automation of various processes in the organization. Well-managed databases can help to provide organization-wide access to the data needed for different business processes.

Additionally, database technology fuels electronic commerce, from helping to display available products for sale to providing customer service. For example, any product information you see on e-commerce sites such as Amazon is dynamically retrieved from databases; any changes to product information, pricing, or shipping estimates do not require changes to the product's web page itself but can be accomplished by simply changing the associated entry in the

## FIGURE 3.7

Dynamic web pages are assembled using data from various databases.

<!-- image -->

database. A customer viewing a product on Amazon receives a web page that is assembled by a web server using data coming from different databases (e.g., containing data about products, inventory, pricing, or customer reviews), a content server (e.g., for product images), and other sources (Figure 3.7); the actual transaction then involves product data, inventory data, customer data, payment data, confirmation emails, and so on. To harness the power of the data contained in the databases, organizations use database management systems (DBMSs) , which are a type of software that allows organizations to more easily store, retrieve, and analyze data.

Finally, databases support storing and analyzing Big Data from a variety of sources. Gaining insights from internal and external sources (such as social media) can provide valuable business intelligence for organizations.

How these data are collected, stored, and manipulated is a significant factor influencing the success of modern organizations. As databases have become a critical component for most organizations, they rely on a solid underlying IS infrastructure (note that sometimes, databases are considered part of the infrastructure; given their importance and role in an organization's business processes, we do not consider them infrastructure). In Chapter 6, 'Enhancing Business Intelligence Using Big Data, Analytics, and Artificial Intelligence,' we talk more about the benefits of effectively and efficiently collecting, storing, and manipulating data stored in databases, data warehouses, or so-called data lakes.

## IS Infrastructure Components

Computing, storage, and networking technologies not only create value by enabling efficiency and effectiveness, but increasingly create value by enabling agility. In recent times, fueled by increasing digital density, a well-functioning IS infrastructure has become essential for organizations, leading to the need for making informed infrastructure decisions. In this section, we will introduce  hardware,  system  software,  storage,  networking,  and  data  centers  and  discuss  how making the right choices about the IS infrastructure can contribute to business success.

## Hardware

A fundamental component of the IS infrastructure is the hardware-that is, the computers that run the applications and databases necessary for processing transactions or analyzing business data. As organizations need to carry out hundreds or thousands of different activities belonging to various business processes, they need different types of computers to support these processes. The six general classes of computers are supercomputer, mainframe, server, workstation, personal computer, and mobile device (Table 3.1). A supercomputer is the most expensive and most powerful kind of computer. Typically, supercomputers are not used by business organizations; they are used primarily to assist in solving massive scientific problems. In contrast, large mainframe computers are used primarily as the main, central computing system for major corporations; optimized for high availability, resource utilization, and security, mainframes are typically used for mission-critical applications, such as transaction processing. A server is any computer on a network that makes access to files, printing, communications, and other services available to  users  of  the  network.  Servers  are  used  to  provide  services  to  users  within  large  organizations or to web users. Servers are optimized for access by many concurrent users and therefore have more advanced microprocessors, more memory, and more disk storage than single-user

TABLE 3.1 Characteristics of Computers Currently Being Used in Organizations

| Type of Computer   | Number of Simultaneous Users   | Physical Size                                                   | Typical Use                                                           | Random Access Memory   | Typical Cost (in US$)   |
|--------------------|--------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------------|------------------------|-------------------------|
| Supercomputer      | One to many                    | Like an auto- mobile to as large as mul- tiple rooms            | Scientific research                                                   | 5,000+ GB              | Up to $200 million      |
| Mainframe          | 1,000+                         | Like a refrigerator                                             | Transaction processing, enterprise-wide applications                  | Up to 3,000+ GB        | Up to $10 million       |
| Server             | 10,000+                        | Like a DVD player and mounted in a rack to fitting on a desktop | Providing web- sites or access to databases, appli- cations, or files | Up to 512 GB           | Up to $50,000           |
| Workstation        | Typically one                  | Fitting on a desktop to the size of a file cabinet              | Engineering, medical, graphic design                                  | Up to 512 GB           | Up to $10,000           |
| Personal computer  | One                            | Fitting on a desktop                                            | Personal productivity                                                 | 512 MBto 32 GB         | Up to $5,000            |
| Mobile device      | One                            | Handheld                                                        | Personal productivity                                                 | 512 MBto 16 GB         | Up to $1,400            |

computers; servers also boast high reliability and fast network connectivity. To support different business processes, organizations often have many different servers in different configurations. For example, whereas some web servers display the same static web pages for every visitor (as is the case with many informational websites), others are designed to dynamically create web pages based on user requests (e.g., Facebook displays content based on each individual user's network of friends); such servers have different requirements (e.g., in terms of processing power, network connectivity, or software) than email servers, print servers, or other types of servers.

In contrast to mainframes and servers, which are designed for multiple concurrent users, workstations and personal computers are typically used by one user at a time. Workstations , designed for medical, engineering, architectural, or animation and graphics design uses, are optimized for visualization and rendering of 3D models and typically have fast processors, large memory, and advanced video cards. Personal computers (PCs) and notebook computers are used for personal computing and small business computing. Finally, mobile devices-tablets and smartphones-have increasingly become part of an organization's information systems infrastructure. In contrast to general-purpose computers, embedded systems are optimized to perform a well-defined set of tasks, ranging from playing MP3 music files to controlling engine performance, traffic lights, or Blu-Ray players. Relatedly, programmable logic controllers (PLCs) are used to automate machines and can control everything from manufacturing processes to ski lifts. In addition to the processing components, IS hardware also encompasses input devices (such as computer mice, touch screens, or cameras) and output devices (such as monitors, printers, or speakers). With the advent of the Internet of Things (IoT), various sensors are used to provide valuable data as input to different processing technologies. A key purpose of IoT sensors is to detect changes in environmental conditions, with dedicated sensors available for measuring anything from temperature to atmospheric pressure, vibration, pressure, or proximity. In addition, controllers and other single-purpose, nontraditional computing devices enable advanced IoT applications. For example, in one of the electronics factories of Siemens, a

## FIGURE 3.8

RFID tags can range in size from being a fraction of an inch up to several inches across.

Source: Albert Lozano/Shutterstock.

<!-- image -->

combination of sensors, PLCs, and manufacturing machines handles 75 percent of the entire production process (and, along the way, generates 50 million pieces of data per day); further, the use of Industrial Internet of Things devices such as sensors and intelligent product codes enables the products to tell the machines what should be done, enabling self-organizing production processes. Another key IoT technology helping to monitor product flows is radio frequency identification (RFID) , which is rapidly replacing the standard bar codes you find on almost every product. RFID uses electromagnetic energy to transmit data between a reader (transceiver) and a processing device, or RFID tag.

RFID tags can be used just about anywhere a unique identification system might be needed, such as on clothing, pets, cars, keys, missiles, or manufactured parts. RFID tags can range in size from being a fraction of an inch, which can be inserted beneath an animal's skin, up to several inches across and affixed to a product or shipping container (Figure 3.8). The tag can carry data as simple as the name of the owner of a pet or as complex as how a product is to be manufactured on the shop floor.

RFID systems offer advantages over standard bar code technologies in that RFID eliminates the need for line-of-sight reading. RFID also does not require time-consuming hand scanning, and RFID data is readable regardless of the entity's position or whether the tag is plainly visible. RFID tags can also contain more data than bar codes. Further, a company can program any data that it wants or needs onto an RFID tag, enabling a vast array of potential uses. Thus, it is possible to retrieve data about an entity's version, origin, location, maintenance history, and other important data and to manipulate that data on the tag. RFID scanning can also be done at greater distances than can bar code scanning. Passive tags are small and relatively inexpensive (starting from a few cents) and typically have a range up to several feet. Active tags, on the other hand, cost upward of US$5, include a battery, and can transmit hundreds of feet. Together with other IoT devices and Big Data, RFID systems have the potential to revolutionize production processes in countless industries (see Chapter 8, 'Strengthening Business-to-Business Relationships via Supply Chain and Customer Relationship Management').

The application software used for various business processes cannot directly interact with these various types of hardware. Rather, the application software interacts with the system software, which, in turn, interacts with the computer hardware.

## System Software

System software is the collection of programs that control the basic operations of computer hardware. The most prominent type of system software, the operating system (e.g., Windows, macOS, Ubuntu Linux), coordinates the interaction between hardware components (e.g., the CPU and the monitor), peripherals (e.g., printers), application software (e.g., office programs), and users, as shown in Figure 3.9. Operating systems are often written in assembly language, a very lowlevel computer programming language that allows the computer to operate quickly and efficiently. The operating system is designed to insulate you from this low-level language and make computer operations unobtrusive. Further, the operating system provides a common layer for different underlying devices so that applications only have to be developed for different operating systems

<!-- image -->

rather than for each different computer model (Figure 3.10); device drivers allow the computer to communicate with various different hardware devices. The operating system performs all of the day-to-day operations that we often take for granted when using a computer, such as updating the system clock, printing documents, or saving data to a hard drive. Just as our brain and nervous system control our body's breathing, heartbeat, and senses without our conscious realization, the system software transparently controls the computer's basic operations. Mobile operating systems, such as Android, Windows 10 Mobile, or iOS, are optimized for mobile devices.

COMMON OPERATING SYSTEM FUNCTIONS. Many tasks are common to almost all computers. These include getting input from a keyboard or mouse, reading from and/or writing to a storage device (such as a hard disk drive), and presenting information to you via a monitor. Each of these tasks is performed by the operating system. For example, if you want to copy a word processing file from a flash drive onto your computer, the operating system makes this very

<!-- image -->

## FIGURE 3.9

Operating systems coordinate the interaction between users, application software, hardware, and peripherals.

## FIGURE 3.10

Operating systems provide a common layer for different underlying devices so that applications only have to be developed for different operating systems rather than for each different computer model.

easy for you, as all it takes is simply using the mouse to point at a graphic icon of the word processing file on the flash drive, then clicking and dragging it onto an icon of your hard disk. The operating system makes this process appear easy. However, underlying the icons and simple dragging operations is a complex set of coded instructions that tell the electronic components of the computer that you are transferring a set of bits and bytes located on the flash drive to a location on your internal hard disk. Imagine if you had to type sets of instructions every time you wanted to copy a file from one place to another. The operating system manages and executes these types of system operations so that you can spend your time on more important tasks.

## Storage

In addition to processing and analyzing vast amounts of data, efficiently storing and retrieving data is key for organizational success. Further, governmental regulations such as the SarbanesOxley Act mandate archiving business documents and relevant internal communication, including email and instant messages. Hence, organizations are faced with the need to reliably process and store tremendous amounts of data, and this storage requirement is growing at an increasing rate. Earlier, we discussed the role of databases in supporting organization-wide business processes. To enable efficient storage and retrieval of the content of such databases (as well as digital content not stored in databases), organizations need to have a solid storage infrastructure. One can distinguish between three distinct types of data, based on their purpose, each with distinct requirements in terms of timeliness, searchability, access speed, and life span (  Figure   3.  11  ):

- ■ Operational data-data used for managing business processes-such as for processing transactions-or for data analysis

<!-- image -->

## COMING ATTRACTIONS

## Gamers Fighting Diseases?

Supercomputers are expensive, physically large, and also happen to be the best choice for dealing with scientific research projects. did you know that the biggest supercomputers aren't even single computers at all? It turns out there is another kind of supercomputer that is just beginning to gain massive influence for scientific research-networks of gamers. Those that play games on their personal computers (affectionately known as 'gamers') care immensely about having the fastest and smoothest gaming experience possible, and therefore invest in expensive and powerful hardware. Well, it turns out that the specialized graphics and processing hardware that enables awesome gaming experiences also happens to be quite good at crunching through scientific research data.

The gamer supercomputer is actually a grid computing implementation (discussed in this chapter), coordinated by the research group Folding@Home. The Folding@Home application distributes research data to the network of computers running their application and uses idle computing power to crunch numbers to solve a scientific research problem. Crunching numbers does not hurt the performance of the computer, because it only works on the research data when the user is away. With the onset of the novel coronavirus pandemic, medical researchers had an urgent need to model how virus proteins behave in the human body (i.e., protein folding). If researchers can understand how the virus behaves, then they can also figure out how to block the virus and develop future therapies.

With the onset of the pandemic, gamers were called to action by nvidia, youTubers, and others in the gaming industry to use their powerful computers to fold proteins for research. Gamers enthusiastically responded and created a supercomputer faster than the top 500 most powerful supercomputers combined. In fact, as of April 2020, Folding@Home was 15 times faster than IBM Summit, the fastest supercomputer to date. With this kind of computing power applied to studying CovId-19, cancers, Alzheimer's, and other diseases, gamers are doing their part to fight current and future diseases.

Based on:

Lilly, P . (2020, April 14). Folding@home is now 15 times faster than any current supercomputer. PC Gamer. Retrieved July 12, 2020, https://www.pcgamer.com/foldinghome-is-now-15-times-fasterthan-any-current-supercomputer nield, d. (2020, April 17). People running Folding@home accidentally created the world's biggest supercomputer. Science Alert. Retrieved July 12, 2020, from   https://www.sciencealert.com/so-many-peopleare-running-folding-home-that-it-s-created-the-world-s-biggestsupercomputer

Ridley,  J.  (2020,  March  26).  Folding@home  is  now  equival ent  to  an  exascale  supercomputer. PC  Gamer. Retrieved J u l y   12,  2020,  from    https://www.pcgamer.com/amp/ folding-home-exascale-supercomputer/

Sheridan, C. (2020, March 13). nvidia's calling on gaming PC owners to put their systems work fighting CovId-19. Games Radar. Retrieved July 12, 2020, from   https://www.gamesradar.com/nvidias-calling-ongaming-pc-owners-to-put-their-systems-to-work-fighting-covid-19

<!-- image -->

- ■ Backup data-short-term copies of organizational data, used to recover from systemrelated disaster (backup data are frequently overwritten with newer backups.)
- ■ Archival data-long-term copies of organizational data, often used for compliance and reporting purposes

These different uses of organizational data call for different physical storage technologies. For example, operational data are typically stored in databases (e.g., data from transaction processing systems or customer data) or files (e.g., business documents, images, or company brochures) using disk-based storage media such as hard drives. Hard drives offer high access speeds and are thus preferred for data that are frequently accessed or where response time is of the essence (as in an e-commerce website); in addition, flash-based storage is increasingly used for situations where access speed is of crucial importance. Likewise, big data analytics requires fast storage to analyze vast quantities of different data. To ensure continuous business operations in case disaster strikes, organizations periodically back up their data to a secure location; often, companies have completely redundant systems to be able to seamlessly continue business if the primary systems fail (see Chapter 10, 'Securing Information Systems'). Storing backup data on hard drives enables quick recovery without slowing the company's operations. Data that are no longer used for operational purposes (such as old internal emails) are archived for long-term storage, typically on magnetic tapes. As data are stored sequentially on magnetic tapes, access speed can be very slow and data is not quickly searchable; however, magnetic tape has a shelf life of up to 30 years, is very low cost as compared to other storage media, and is removable, meaning that it is highly expandable and tapes can be easily stored in a secure, remote location (see the Technology Briefing for more on different storage technologies).

## Networking

As you have seen, organizations depend on a variety of different applications, hardware, and storage technologies to support their business processes: Organizations have servers, mainframes, personal computers, storage devices, mobile devices, environmental control systems, and various other devices. Yet, taken alone, each individual piece of technology has little value; it is through connecting the different pieces that business value can be realized: For example, the bestperforming database would be useless if it could not be accessed by those people or applications throughout the organization that depend on the data. Further, one of the reasons why information systems have become so powerful and important is the ability to interconnect, allowing internal and external constituents to communicate and collaborate with each other, and many innovative business models would not exist without the internet. The infrastructure supporting this consists of  a  variety  of  components,  such  as  the  networking  hardware  and  software  that  facilitate  the interconnection of different computers, enabling collaboration within organizations, across organizations, and literally around the world.

## FIGURE 3.11

Operational, backup, and archival data have different requirements.

## FIGURE 3.12

Communication requires senders, a message to share, and receivers.

## FIGURE 3.13

Coding, sending, and decoding a message.

<!-- image -->

HUMAN COMMUNICATION AND COMPUTER NETWORKING. Human communication involves the sharing of information and messages between senders and receivers. The sender of a message formulates the message in his brain and codes the message into a form that can be communicated to the receiver-through voice, for example. The message is then transmitted along a communication pathway to the receiver. The receiver, using her ears and brain, then attempts to decode the message, as shown in Figure 3.12. This basic model of human communication helps us to understand telecommunications or computer networking. Computer networking is the sharing of data or services. The information source produces a message, which is encoded so that it can be transmitted via a communication channel; a receiver then decodes the message so that it can be understood by the destination. Thus, analogous to human communication, computer networks require three things:

- ■ A sender (source) and a receiver (destination) that have something to share (a message)
- ■ A pathway or transmission medium, such as a cable, to send the message
- ■ Rules or protocols governing communication between senders and receivers

The easiest way to understand computer networking is through the human communication model. Suppose you are applying for a job in France after graduation. You need information about different employers. The first requirement for a network-information to share-has now been met. After contacting a few potential employers, a company sends you information about its hiring process (the encoded message) via email. This is the second requirement: a means of transmitting the coded message. The internet is the pathway or transmission medium used to send the message. Transmission media refers to the physical pathway-cable(s) and wirelessused to transmit data. At this point, you may run into some difficulties. If the potential employer has sent you information in French, you may not understand what he or she has written-that is, decode the message-if you don't speak French; if the message is not understood by the receiver, there is no communication. Although you have contacted the receiver, you and the receiver of your message must meet the third requirement for successful communication: You must establish a language of communication-the rules or protocols governing your communication. Protocols define the procedures that different computers follow when they transmit and receive data. You both might decide that one communication protocol will be that you communicate in English. This communication session is illustrated in Figure 3.13.

<!-- image -->

COMPUTER NETWORKS. A fundamental difference between human and computer communication is that human communication consists of words, whereas computer communication consists of bits, the smallest unit of data used by computers. Virtually all types of content can be transmitted on a computer network-documents, art, music, or film-although each type has vastly different requirements for effective transmission. For example, a page of text is approximately 14 KB of data, whereas a publication-quality photograph could be larger than 200 MB of data. Similarly, to support different business processes, businesses operating in the digital world transmit vast amounts of data, ranging from customer data to sales data to design blueprints. To transmit such vast amounts of data in a timely manner from one location to another, adequate bandwidth is needed. Bandwidth is the transmission capacity of a computer or communications channel, measured in bits per second (bps) or multiples thereof, and represents how much binary data can be reliably transmitted over the medium in one second. To appreciate the importance of bandwidth for speed, consider how long it would take to download a 45-minute TV show (about 200 megabytes) from iTunes. It would take about six minutes at 1 megabit per second (Mbps) (regular cable or DSL connection) and two minutes at 15 Mbps (high-speed cable or DSL connection). In contrast, using an old-fashioned PC modem that transmits data at a rate of 56 kilobits per second (Kbps), it would take almost nine hours to download the same TV show. Hence, different types of information have different communication bandwidth requirements. Typical local area networks have a bandwidth of 10 Mbps to 1 Gbps.

Telecommunications advances have enabled individual computer networks-constructed with different hardware and software-to connect together in what appears to be a single network. Networks are increasingly being used to dynamically exchange relevant, value-adding information and knowledge throughout global organizations and institutions. The following sections take a closer look at the fundamental building blocks of these complex networks and the services they provide.

Servers, Clients, and Peers Computers in a network typically have one of three distinct roles-servers, clients, and peers-as depicted in Figure 3.14. A server is any computer on the network that makes access to files, printing, communications, and other services available to users of the network. Servers only provide services. A client is any computer, such as a user's PC or laptop, on the network or any software application, such as Microsoft's Outlook email client, that uses the services provided by the server. Clients only request services. A client usually has only one user, whereas many different users share the server. So-called thin clients -microcomputers with minimal memory, storage, and processing capabilities-use desktop virtualization to provide workers with a virtual desktop environment, helping to reduce costs for software licensing or maintenance and to comply with stringent privacy and data protection laws. A peer is any computer that may both request and provide services. Businesses typically use client-server networks , in which servers and clients have defined roles. With ubiquitous access to company local area networks (LANs) and the internet, almost everyone works in a client-server environment today. In contrast, peer-to-peer (P2P) networks enable any computer

<!-- image -->

## FIGURE 3.14

A server is a computer on the network that enables multiple computers (or 'clients') to access data or services. A peer is a computer that may both request and provide services.

TABLE 3.2 Types of Networks

| Type                        | Usage                                                                              | Size                                                                                                    |
|-----------------------------|------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|
| Personal area network (PAN) | Wireless communication between devices, using technolo- gies such as Bluetooth     | Under 10 meters                                                                                         |
| Local area network (LAN)    | Sharing of data, software appli- cations, or other resources between several users | Typically within a building                                                                             |
| Wide area network (WAN)     | Connect multiple LANs, often with distributed ownership and management             | Large physical distance, from spanning multiple buildings or the area of a city to worldwide (internet) |

or device on the network to provide and request services; these networks can be found in small offices and homes. In P2P networks, all peers have equivalent capabilities and responsibilities; this is the network architecture behind the internet telephony service Skype and file-sharing protocols such as BitTorrent, which allow peers to connect directly to the hard drives of other peers on the internet that are utilizing the software.

Types of Networks Computing networks are commonly classified by size, distance covered, and structure. The most commonly used types are personal area networks , local area networks , and wide area networks (Table 3.2). These networks are typically used to connect devices within an organization or across organizational subunits. Wide area networks can range from spanning multiple buildings (sometimes called a campus area network ) to covering the area of a city (sometimes called a metropolitan area network ) to worldwide (the internet). To enable the connection of mobile devices or to install a network where running cables is infeasible, organizations install wireless local area networks (WLANs) using high-frequency radio-wave technology; WLANs are also referred to as Wi-Fi (wireless fidelity) networks . The ease of installation has made WLANs popular for business and home use, and public WLANs can nowadays be found almost anywhere. For many applications (especially IoT devices), 5G wireless networks offer much promise, such as extremely low latency and high transmission speed. For more on the different types of networks, see the Technology Briefing.

THE INTERNET. One global network that has enabled organizations and individuals to interconnect in a variety of ways is the internet , a large worldwide collection of networks that use a common protocol to communicate with each other. The name internet is derived from the concept of internetworking, which means connecting host computers and their networks together to form even larger networks.

WORLD WIDE WEB. One of the most powerful uses of the internet is the World Wide Web. The World Wide Web is a system of interlinked documents on the internet, or a graphical user interface to the internet, that provides users with a simple way to access a wide variety of content. web browser .

A key feature of the web is hypertext . A hypertext document, otherwise known as a web page , contains not only content but also hyperlinks , which are references or links to other documents. The standard method of specifying the structure and content of web pages is called Hypertext Markup Language (HTML) . The source code of a web page uses codes, or markup tags, that specify the structure and content of a document. These web pages are stored on web servers , which process user requests for pages using the Hypertext Transfer Protocol (HTTP) . Web servers typically host a collection of interlinked web pages (called a website ) that are owned by the same organization or by an individual. Websites and specific web pages within those sites have a unique internet address. A user who wants to access a web page enters the address, and the web server hosting the website retrieves the desired page from its hard drive and delivers it to the user. In addition, web servers often employ scripting languages to assemble pages on the fly or retrieve data from databases and insert it into the page presented to the user (see the Technology Briefing). As data traveling between a server and a user's computer can

<!-- image -->

easily be intercepted and there are growing concerns about legitimate and illegitimate monitoring of web traffic, many organizations now routinely use the more secure HTTPS protocol for any data that are being transmitted over the web (a padlock icon in your browser's address bar signals that a secure protocol is being used).

Web Domain Names and Addresses A Uniform Resource Locator (URL) is used to identify and locate a particular web page. For example, www.google.com is the URL used to find the main Google web server. The URL has three distinct parts: the domain, the top-level domain, and the host name (Figure 3.15).

The domain name is a term that helps people recognize the company or person that the domain name represents. For example, Google's domain name is google.com. The prefix google lets you know that it is very likely that this domain name will lead you to the website of Google. Domain names also have a suffix that indicates which top-level domain they belong to. For example, the '.com' suffix is reserved for commercial organizations. Some other popular suffixes are listed here:

- ■ .edu-educational institutions
- ■ .org-organizations (typically nonprofit organizations)
- ■ .gov-U.S. government entity
- ■ .de-Germany (there are more than 240 two-letter country code top-level domains)

Domain names can be registered through many different companies (known as registrars) that compete with one another. Given the proliferation of domain names, more generic top-level domains (gTLDs) have been added, such as .aero for the air transport industry, .name for individuals, .coop for business industry cooperatives, and .museum for museums. In 2012, the ICANN (Internet Corporation for Assigned Names and Numbers-the organization that coordinates the domain name system) relaxed the strict rules for gTLDs so that regions, businesses, or other entities can apply for their own gTLD. For example, new gTLDs include .bike, .club, .tips, and .cab as well as many other gTLDs coming soon. The new gTLDs also allow for the use of non-Latin characters, such as in the Russian gTLD.ohπa h (meaning 'online').

The host name is the particular web server or group of web servers (if it is a larger website) that will respond to the request. In most cases, the 'www' host name refers to the default website including the home page of the particular domain. Other host names can be used. For example, drive.google.com will take you to the group of web servers that are responsible for serving up Google's cloud-based storage for documents. Larger companies have several host names for their different functions. Some examples used by Google are the following:

- ■ https://mail.google.com (Google's free email service)
- ■ https://photos.google.com (Google's application for organizing and editing photos)
- ■ https://maps.google.com (Google's mapping service)

All the domain names and the host names are associated with one or more internet protocol (IP) addresses. IP addresses serve to identify all the computers or devices on the internet. The IP address serves as the destination address of that computer or device and enables the network to route messages to the proper destination. Traditionally, the format of an IP address (version 4) is a 32-bit numeric address written as four numbers separated by periods (the latest version, IPv6 uses 128-bit addresses, enabling more devices to be connected to the internet). Each of the four

## FIGURE 3.15

Dissecting a URL.

numbers can be any number between 0 and 255. For example, 128.196.128.233 is an underlying IP address of www.arizona.edu, the University of Arizona's main web page.

IP addresses can also be used instead of URLs to navigate to particular web addresses. This practice is not done regularly, as IP addresses are far more difficult to remember than domain names, and an organization may assign its domain name to a server with a different IP address; for example, whereas the IP address behind google.com may change, the domain name stays the same.

In addition to specifying the address of the web server, URLs typically also include the path to the requested resource, such as a particular page located in a particular directory (e.g., https:// eller.arizona.edu/departments-research/directory-expertise).

World Wide Web Architecture The web consists of a large number of interconnected web servers, which host the pages users access with their web browsers. The internet uses the Transmission Control Protocol/Internet Protocol (TCP/IP) to facilitate the transmission of web pages and other information. Users can access web pages by entering the URL of the web page into their web browser. Once the user enters the URL into the address bar of the web browser, TCP/IP breaks the request into packets and routes them over the internet to the web server where the requested web page is stored. When the packets reach their destination, TCP/IP reassembles them and passes the request to the web server. The web server understands that the user is requesting a web page (indicated by the http:// or https:// prefix in the URL) and retrieves the web page, which is packetized by TCP/IP and transmitted over the internet back to the user's computer. TCP/IP reassembles the packets at the destination and delivers the web page to the web browser. In turn, the web browser translates the HTML code contained in the web page, formats its visual appearance, and displays the results. If the web page contains a hyperlink, the user can click on it and the process repeats.

APIs. Web protocols are not only used to transmit web page data but are also used to enable applications to communicate with each other, which is the basis for APIs. As described in Chapter 1, an API lets a service consumer (e.g., the Uber app on your phone) access services provided by a service provider (e.g., Google Maps), without the service consumer having to know how the underlying services are created. As an interface, the service consumer needs to pass various pre-specified parameters (for example, the rider's location and destination) to the service provider, which would return the requested service (i.e., the optimal route). Whereas APIs use various types of protocols, a good illustration of a URL-based API is the Google Maps API; in order for an application to obtain directions, it needs to pass the parameters via a URL in a specified format. For the Google Maps API, the format would look as follows, where 'your\_ api\_key' would be a unique key assigned to a service customer: https://maps.googleapis.com/ maps/api/directions/json?origin=Barcelona&amp;destination=Frankfurt&amp;key=YOUR\_API\_KEY. As you can see, the minimum parameters needed are the origin, the destination, and the unique key; Google then provides the route to the service consumer.

The Deep Web In addition to searchable content on the web, much content cannot be indexed by search engines such as Google. The term deep web refers to those parts of the web that cannot be indexed by conventional search engines. The common web (called 'surface web') that you know and use every day-sites like YouTube, Google, Wikipedia, and news agenciescomprises as little as 1 percent of the total size of the web. Beyond this surface, the deep web is composed of tens of trillions of web pages that most people have never seen. The deep web consists of private areas requiring authentication, dynamic web pages created from connected databases, and static web pages that are not connected to other pages via hyperlinks. Some of this content is in public databases, such as data from the U.S. National Oceanic and Atmospheric Administration, NASA, or the Patent and Trademark Office. Search engines cannot traverse such pages because their contents are dynamically generated from databases and displayed on demand based on database queries. Other databases are private or behind a paywall, such as the government documents on LexisNexis and Westlaw or the academic journals on Elsevier. Organizations that maintain these databases charge users and institutions for access, and their contents are thus not freely available for search engine indexing. In addition, internal content behind corporate or university firewalls is not accessible to search engines. Not to be confused with the deep web, the term dark web is used to refer to those areas of the World Wide Web that

<!-- image -->

Running the Alphabet (i.e., Google) empire requires a tremendous amount of electricity, not just in the united States but throughout the world. To reduce its carbon footprint, Alphabet is aggressively transitioning to renewable sources. The company has a widely publicized goal to use 100 percent clean energy by 2025. To reach this goal, Alphabet is signing long-term contracts with clean energy providers, investing in clean energy companies, and building its own 'green' facilities. Alphabet has focused on renewable energy for a long time. In 2007, for example, Google had the largest corporate solar panel installation of its kind, generating 1.7 megawatts on its Mountain view, California campus. It also operates a natural gas-powered generator at the local landfill, producing 990 kilowatts to provide for its electrical needs.

Alphabet is truly a global leader in renewable energy; long-term contracts with clean energy providers range from a 490-megawatt project in Texas to a 286-megawatt project in Sweden and more than 125-megawatts in Chile. In addition to these contracts, it is also investing uS$2 billion in additional wind and solar projects throughout the world to improve the clean energy infrastructure.

it is not just the tech companies; Alcoa, Bank of America, CocaCola, uPS, and Walmart, to name a few, are making strong commitments to renewable energy. While the move to renewable is good corporate responsibility, it is also good business. developing a comprehensive plan that includes long-term contracts and investments will help to lock in prices, improve reliability throughout the world, and signal customers about the company's commitment to a clean energy and sustainability.

Based on:

Ambrose, J. (2019, September 20). Google signs up to $2bn wind and solar investment. The Guardian. Retrieved June 10, 2020, from https://www.theguardian.com/technology/2019/sep/20/google-saysits-energy-deals-will-lead-to-2bn-wind-and-solar-investment

Koksal, I. (2019, october 2). A massive investment: Google announces 18 new renewable energy deals. Forbes. Retrieved June 10, 2020, from   https://www.forbes.com/sites/ilkerkoksal/2019/10/02/a-massiveinvestment-google-announces-18-new-renewable-energy-deals

Lee, A. (2019, october 16). Google in renewable energy investment plan to spur $1.5bn. Recharge News. Retrieved June 10, 2020, from https://www.rechargenews.com/transition/google-in-renewableenergy-investment-plan-to-spur-1-5bn/2-1-689830

By late 2019, Alphabet had increased its renewable energy capacity to nearly 5.5 gigawatts. To put that another way, Google has built or contracted the same amount of clean energy as the energy consumed by 600 million LEd bulbs, or the energy delivered by 11,000 Corvette Z06s. In addition, other tech giants such as Facebook, Amazon, Microsoft, and Apple are also embracing the move to renewable energy. And

Mueller, M. &amp; Rumph, M. (2019, August 12). How much power is 1 gigawatt? Office of Energy Efficiency &amp; Renewable Energy . Retrieved July 16, 2020, from   https://www.energy.gov/eere/articles/ how-much-power-1-gigawatt

Williams,  A.  (2019,  September  20).  Google  warms  to  biggest renewable energy deal. Electronics Weekly. Retrieved June 10,  2020,  from    https://www.electronicsweekly.com/news/ google-warms-biggest-renewable-energy-deal-2019-09

are used for various nefarious purposes (such as trading drugs, stolen credit card information, or illegal porn) and that are typically only accessible using specialized browsers that anonymize the user and hide traces   (see   Chapter   10  , 'Securing Information Systems')  .

INTRANETS AND EXTRANETS. As organizations have realized the advantage of using the internet and web to communicate public information outside corporate boundaries, they can also leverage web-based technologies to support proprietary, internal communications through the implementation of an intranet . An intranet looks and acts just like a publicly accessible website and uses the same software, hardware, and networking technologies to transmit and display data. All intranet pages are behind the company's firewall , which secures proprietary data stored within the corporate local area network and/or wide area network so that the data can be viewed only by authorized users.

In the simplest form of an intranet, communications take place only within the confines of organizational boundaries and do not travel across the internet. Organizations can use intranets for disseminating corporate information, employee training, project management, collaboration, or enabling employee self-service for administering benefits, managing retirement plans, or other human resources-based applications through employee portals .

Increases in employees' mobility necessitate that an intranet be accessible from anywhere. Thus, most companies allow their employees to use virtual private networks (VPNs) to securely connect to the company's intranet while on the road or working from home (i.e., telecommuting).   Figure   3.  16 depicts a typical intranet system architecture   (see   Chapter   10 for more on firewalls and VPNs)  .

## FIGURE 3.16

Typical intranet system architecture.

## FIGURE 3.17

Typical extranet system architecture.

<!-- image -->

Similar to an intranet, an extranet , which can be regarded as a private part of the internet that is cordoned off from ordinary users, enables two or more firms to use the internet to do business together. Although the content is 'on the web,' only authorized users can access it after logging on to the company's extranet website. As an extranet uses the public (and normally insecure) internet infrastructure to connect two or more business partners, it often uses VPNs to ensure the secured transmission of proprietary information between business partners (Figure 3.17). To access information on an extranet, authorized business partners access their business partner's main extranet web page using their web browsers. Table 3.3 summarizes the similarities and differences between intranets, extranets, and the internet.

Extranets benefit corporations in a number of ways. For example, extranets can dramatically improve the timeliness and accuracy of communications, reducing the potential for misunderstandings within the organization as well as with business partners and customers. In the business world, very little information is static; therefore, information must be continually updated and disseminated as it changes. Extranets facilitate this process by providing a costeffective, global medium over which proprietary information can be distributed. Furthermore, they allow central management of documents, thus reducing the number of versions and the amount of out-of-date information that may be stored throughout the organization. While security is still considered to be better on proprietary networks, the internet can be used as a relatively secure medium for business. Further, a company can use extranets to automate business transactions, reducing processing costs and achieving shortened cycle times. Extranets can also

<!-- image -->

TABLE 3.3 Characteristics of the Internet, Intranet, and Extranet

|          | Focus                   | Type of Content                              | Users                                | Access                    |
|----------|-------------------------|----------------------------------------------|--------------------------------------|---------------------------|
| Internet | External communications | General, public content                      | Any user with an internet connection | Public and not restricted |
| Intranet | Internal communications | Specific, corporate, and proprietary content | Authorized employees                 | Private and restricted    |
| Extranet | External communications | Communications between business partners     | Authorized busi- ness partners       | Private and restricted    |

reduce errors by providing a single point of data entry from which the data can be updated on disparate corporate computing platforms without having to reenter the data. Management can then obtain real-time data to track and analyze business activities.

## Data Centers

To satisfy the increasing requirements for processing and storing the ever-growing volume of data, large organizations need hundreds, or even thousands, of servers. Organizations such as UPS need tremendous amounts of computing power to route and track packages, online stores such as Zappos need to provide product information and track customer orders, and social networking game developers such as Epic Games need to track each and every action users take on the popular game Fortnite. As you can imagine, an organization's hardware and storage infrastructure can quickly grow quite large, and companies typically set aside dedicated space for their infrastructure components (such data centers can range in size from a single dedicated server room to buildings the size of a large warehouse). Storing and processing massive amounts of data requires lots of power as well as air-conditioning to keep the equipment running within the optimal temperature range (which helps increase the life span of the equipment). Keeping this infrastructure in one location helps in managing, repairing, upgrading, and securing the equipment, and organizations go to great lengths in selecting locations that strike the optimal balance between protection from the elements (such as earthquakes or hurricanes) and proximity to the customers/users (to reduce latency).

Today, almost any business can be considered an e-business. Given that data are the lifeblood of almost all organizations, reliably accessing these data is a key concern. This is especially true for data-intensive organizations, ranging from e-commerce companies to logistics companies to government agencies. All such organizations are striving for the highest level of availability of their hardware, storage, and networking components, often reaching for 'five-nines' (i.e., 99.999 percent availability, which translates into just over five minutes of downtime per year). To ensure this availability, there are not only specific demands for the individual components (e.g., being able to quickly swap hard drives or other parts in case of failure) but also for the data center overall (e.g., in terms of connectivity, floor space, provision of energy and cooling, and security). In addition, data centers need to be modular to be easily expandable in case of changing needs. The facilities for UPS in Atlanta, Georgia, and Mahwah, New Jersey, are prime examples of such high-availability facilities. To ensure uninterrupted service, the data centers are self-sufficient, and each can operate for up to 2 days on self-generated power. The power is needed not only for the computers but also for air-conditioning, as each facility needs air-conditioning capacity equaling that of more than 2,000 homes. In case power fails, the cooling is provided using more than 600,000 gallons of chilled water, and the UPS facilities even have backup wells in case the municipal water supply should fail. Other protective measures include raised floors (to protect from floods) and buildings designed to withstand winds of 200 miles per hour. Alternatively, organizations can rent space for their servers in collocation facilities, which are data centers managed by a third party that rents out space to multiple organizational customers (see Chapter 10 for more on securing data centers and collocation facilities).

## FIGURE 3.18

Key drivers for evolving the IS infrastructure.

## Key Drivers for Evolving the IS Infrastructure

Needless to say, for organizations, obtaining, operating, maintaining, and upgrading the information systems infrastructure can be a tremendous challenge, especially when these tasks are not part of their core business.

As you have undoubtedly noticed, computing technology has evolved rapidly and will most likely continue to evolve rapidly in the future. In general, because of the increasing pace of change with modern technologies, most organizations face accelerating obsolescence of their hardware and software investments as well as increasing storage and space constraints, demand fluctuations, and increasing energy costs (Figure 3.18). In the following section, we discuss how the interplay between the different infrastructure components both encourages and necessitates continuous upgrading of the infrastructure.

## Rapid Obsolescence and Shorter IT Cycles

Over the past 75 years, information systems have gone through many radical changes. Rapid advances in both hardware and software capabilities have enabled or facilitated many business processes, and organizations are continuously faced with the need to upgrade the IS infrastructure to gain or maintain competitive advantage. In this section, we discuss the history of computing as well as the effects of rapid advances in technology.

BRIEF HISTORY OF COMPUTING. When the Zuse Z1 Computer (a mechanical computer using program punch cards) was introduced in 1936, almost all business and government information systems consisted of file folders, filing cabinets, and document repositories. Huge rooms were dedicated to the storage of these records. Information was often difficult to find, and corporate knowledge and history were difficult to maintain. Only certain employees knew specific information. When these employees left the firm, so did all their knowledge about the organization. The computer provided the solution to the information storage and retrieval problems facing organizations up to the 1940s. Shifts in computing eras were facilitated by

<!-- image -->

fundamental changes in the way computing technologies worked. Each of these fundamental changes is referred to as a distinct generation of computing. Table 3.4 highlights the technology that defined the six generations of computing.

MOORE'S LAW. In 1965, Intel cofounder Dr. Gordon Moore hypothesized that the number of transistors on a chip would double about every 2 years. When Moore made this bold prediction, he did not limit it to any specified period of time. This prediction became known as Moore's law . Interestingly, whereas the first CPU had 2,200 transistors, the newest models have broken the 5-billion-transistor mark, so Dr. Moore's prediction has been fairly accurate so far (see www.intel.com/technology/mooreslaw). The number of transistors that can be packed into a modern CPU and the speed at which processing and other activities occur are remarkable. For example, the Intel Core i7 Extreme CPU can complete hundreds of millions of operations every second. Given technological and economic limitations, today's gains in computing power are increasingly being realized by adding more computing cores that can perform tasks in parallel. Further, advances in quantum computing promise a leap in computing power.

FASTER IT CYCLES AND CONSUMERIZATION. For organizations, this increase in capabilities is both a blessing and a curse. On the one hand, increases in processing power enable applications that were previously not possible; on the other hand, managers must continuously think about when to upgrade the hardware components of the IS infrastructure. Beyond Moore's law, there are two other factors exacerbating this problem. First, IT cycles are becoming increasingly faster, with manufacturers releasing new devices at an ever-increasing pace. Whereas traditionally,

TABLE 3.4 Six Generations of Computing

|   Generation | Time Period   | Major Characteristic              | Events                                                                                                                                                                                             |
|--------------|---------------|-----------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|            1 | 1946-1958     | Vacuum tubes                      | • Mainframe era begins • ENIAC and UNIVAC were developed                                                                                                                                           |
|            2 | 1958-1964     | Transistors                       | • Mainframe era expands • UNIVAC is updated with transistors                                                                                                                                       |
|            3 | 1964-1990s    | Integrated circuits               | • Mainframe era ends • Personal computer era begins • IBM 360 with general purpose operating system • Microprocessor revolution: Intel, Microsoft, Apple, IBM PC, MS-DOS                           |
|            4 | 1990s-2000    | Multimedia and low-cost PCs       | • Personal computer era ends • Interpersonal computing era begins • High-speed microprocessors and networks • High-capacity storage • Low-cost, high-performance integrated video, audio, and data |
|            5 | 2000-2010     | Widespread internet accessibility | • Interpersonal computing era ends • Internetworking era begins • Ubiquitous access to internet with a broad variety of devices • Prices continue to drop; performance continues to expand         |
|            6 | 2010-present  | Ubiquitous mobile connectivity    | • Advent of powerful mobile devices and ubiquitous mobile connectivity • Cloud computing era begins • Big Data • Internet of Things • Social networking                                            |

## FIGURE 3.19

New hardware enables more powerful software; more powerful software often requires new hardware.

IS managers would think in terms of 5 years, nowadays new versions of devices are released every 6-12 months. Second, with the increasing trend toward consumerization of IT, managers must consider how to integrate their users' various mobile devices into the organization's IS infrastructure. We discuss mobile device management in Chapter 10.

SOFTWARE OBSOLESCENCE. In addition to constant increases in hardware capabilities, companies such as Microsoft are continuously developing new and improved software that uses this power to help people be more productive. New operating systems such as Windows 10 can use new processor architectures and offer a richer set of features than older operating systems such as Windows XP. However, these new operating systems often require new hardware, and older-generation application software may not be compatible with the new operating system (Figure 3.19). Further, new generations of application software promise better performance and more (or improved) features, enabling higher productivity. One example is Microsoft Office 2007 (and its most recent successor, Office 365); when developing Office 2007, Microsoft conducted many usability studies to improve the human-computer interface (see Chapter 9, 'Developing and Acquiring Information Systems') to facilitate the execution of common tasks and, as a result, introduced the so-called 'Ribbon' interface. Although people used to the 'old' interface were initially reluctant to switch-because of the associated learning curve-many have now realized the benefits this new feature brings. Manufacturers of hardware and software often apply the concept of planned obsolescence , meaning that the product is designed to last only for a certain life span. For hardware, this can mean that certain components are not built to be serviceable, and the device must be replaced once one of these components breaks down; similarly, older versions of software may not be able to open newer file formats, or a company may cease support for a product (mainstream support for the Windows XP operating system ended in 2009, and paid support as well as critical security updates ended in 2014), effectively forcing users to switch to newer versions. Hence, organizations are constantly faced with the decision of when and how to upgrade their current information systems infrastructure. Although such upgrades may increase productivity, often they do not but are still a large cost factor, both in terms of costs for hardware and software and in terms of the time and resources needed for upgrading tens, hundreds, or thousands of computers. Further, the rapid obsolescence of computer hardware carries a high price tag for the environment in terms of resources needed both to manufacture the new systems and to dispose of the old ones (Figure 3.20).

## Big Data and Rapidly Increasing Storage Needs

Another issue facing organizations is the amount of data available and the amount of data needed to stay ahead of the competition. Today, organizations can collect and analyze vast amounts of data for business intelligence (see Chapter 6) and other purposes (such as compliance). For example, organizations can analyze each visitor's actions on the company's website to improve the site's performance. Similarly, organizations are increasingly trying to make use of Big Data, that is, trying to analyze structured and unstructured data from media reports, social media, customer

Powerful Software

<!-- image -->

<!-- image -->

support calls, and other sources. Obviously, capturing more data requires ever more storage space and ever more powerful computing hardware and database management systems for managing and analyzing the data. Further, internet bandwidth grew tremendously during the dot-com bubble, allowing organizations to provide their customers with richer (and more bandwidth-hungry) content. At the same time, services such as  YouTube and videos streamed by Netflix create a need for even more bandwidth. Hence, this is another example of a 'vicious circle' where enhanced capabilities enable new applications, which in turn require a certain level of capabilities in terms of both data and communications infrastructure.

## Demand Fluctuations

An additional challenge for many organizations is that the demands for computing resources are often fluctuating, leading to either having too few resources at some times or having too many idle resources most of the time (according to estimates, up to 70 percent of organizations' IS infrastructures are utilized at only 20 percent of their capacity). Companies engaged in (or supporting) business-to-consumer electronic commerce (such as Amazon or FedExsee Chapter 4, 'Enabling Business-to-Consumer Electronic Commerce'), for instance, face large spikes in demand during the pre-holiday season in December; consequently, increased capacity is needed to handle this demand. While it is relatively easy to hire temporary staff to handle an increase in orders, it is typically not that easy to make quick changes to the IS infrastructure based on changing needs. Just a few years ago, launching a startup involved purchasing lots of hardware and installing web servers in one's basement, with no real idea of how much demand would need to be met; fluctuation in demand for computing resources is especially difficult to cope with for new entrants who are not able to forecast demand and may not have the resources to quickly expand their IS infrastructure to meet increases in demand for their products or services.

For organizations with a growing customer (or user) base, the facilities infrastructure has to grow along with any increase in computing needs (as Google grew, it eventually had to move its equipment out of a friend's garage; now Google has more than 20 major data centers). This can be especially problematic for fast-growing companies, as renting (let alone building) additional facilities is expensive and significant time is needed for locating the right facilities, contract negotiations, and setup of the hardware and software; further, long-term contracts limit the companies' flexibility to scale the infrastructure down in times of lower demand.

## FIGURE 3.20

The rapid obsolescence of computer hardware carries a high price tag for the environment.

Source: Tonis valing/Shutterstock.

## Increasing Energy Needs

Finally, the worldwide increase in demand for energy has become another concern for organizations. As computers process data, they consume electricity; further, various components (such as the CPU and the power supply) generate heat, and most computers have multiple fans to control the temperature. More powerful hardware needs more energy to enable the increase in computing power; at the same time, having more powerful hardware requires more energy for cooling. A typical desktop uses between 40 and 170 watts when idling and can use up to 300 watts or more under full load. A typical server rack (holding multiple servers) in a data center can easily consume 15-17 kilowatts, the equivalent of power needed for more than 10 homes. Although you may not feel the impact of your personal computer usage on your home energy bill, for organizations having hundreds or thousands of computers, rising energy costs are becoming a major issue. Further, power consumption and heat emissions continue to rise as hardware manufacturers pack more and more processing power into servers, often without providing much improvement in energy efficiency. Thus, power and cooling can be significant cost factors for companies. Google has invested many resources into developing more efficient data centers. Google now uses modular data centers that use specially equipped shipping containers for housing servers to be able to maximize efficiency by optimizing airflow, cooling, and power transformation (we will talk more about another trend, 'green computing,' later in the chapter as well as throughout the book in the Green IT case).

## Lean Startups and the Need for Agility

As discussed in Chapter 2, modern organizations must constantly innovate to stay abreast of the competition. Rather than building their businesses around their current competencies, organizations must take an outside-in approach to discover current and future customers' jobs-to-be-done and  come  up  with  innovative  solutions  for  these  jobs.  For  organizations,  being  ahead  of  the competition necessitates speed, so traditional approaches to developing products or services will not work in the long run. Consequently, organizations must adopt an agile mindset, following approaches pioneered by the startup world. The lean startup methodology is one such approach, focusing on rapid cycles of devising new solutions and developing minimum viable products, to quickly be able to test if the solutions have the desired effects. Yet such experiments often require different types of infrastructure, and it makes little sense to invest time and money into infrastructure changes before even knowing whether the 'experiment' will be a success. For example, it would make little sense to purchase new servers for supporting a mobile app without knowing that the app would be accepted by the market. Likewise, it would make little sense to purchase new workstations for running certain big data analytics without knowing that the analytics would bring about the expected results.

Given these issues, organizations have been looking for ways to better manage their IS infrastructure to enhance flexibility and agility while reducing costs. In the following section, we will discuss cloud computing and how it can address some of these infrastructure-related challenges.

## Cloud Computing

Managing the IS infrastructure can be a challenge for many organizations due to the evolution of hardware and software, the demand for more storage and networking bandwidth, and the rising costs of energy. Further, organizations need dedicated staff to support their infrastructure, which incurs further costs; often, managing the IS infrastructure is not among the organization's core competencies, so others may be better at managing the infrastructure for them.

In many organizations, the infrastructure has grown over the years, leading to a fragmented infrastructure that tends to be difficult to consolidate. However, efficiency, effectiveness, and agility are key for successfully competing in the digital world, and organizations require a flexible, scalable infrastructure for their applications and databases. As a result, over the past decades, there has been a shift away from thinking about developing and maintaining the IS infrastructure toward thinking about what services the infrastructure should deliver. For example, people and organizations just want to be able to use email rather than having to think about purchasing an email server and dealing with associated issues such as administration, maintenance, storage, energy consumption, and so on. In addition, organizations increasingly buy or rent, rather than build, applications (except for highly specialized systems that help gain or sustain competitive

<!-- image -->

## WHEN THINGS GO WRONG

## Old and Dirty Energy Drives Global Internet Growth

The internet has become central to nearly every aspect of the modern economy. While traditional web browsing, shopping, and sending email on a desktop or notebook computer are still important and widely performed activities, the internet is being increasingly utilized for entertainment where highdefinition video can be viewed from every corner of world on a smartphone, a tablet, or even a watch. In the coming years, IoT gadgets and sensors will communicate with massive data centers through ubiquitous networks, and autonomous vehicles will take you to work or deliver your online purchases. Clearly, the reliance of society on the internet, and all its related infrastructural components, is going to continue to rapidly increase throughout the world. In fact, the amount of data generated by all of this activity is growing at an estimated 20 percent a year. Additionally, as smartphones have become mainstream in the developing world, there were 4.57 billion active internet users (i.e., a 59 percent global internet penetration) in 2020. And, with IoT, the number of devices connected to the internet will be almost three times the global population by 2021 (more than 25 billion). The biggest driver of data usage has been online video, where Tv and movies accessed through streaming services like youTube, netflix and Hulu have become a method of mainstream information gathering and entertainment across the globe.

67 percent of the electricity needs for major tech companies in China. In fact, a recent Greenpeace evaluation reports that China scored zero points on renewable energy.

one of the challenges for transforming the world to cleaner and more renewable energy is not only the relatively low price for coal but also the subsidies funneled into fossil fuel production, estimated to be more than uS$5 trillion worldwide each year. not all is lost, however. Energy activists, technology companies, and governments are prioritizing a shift to renewable energy. With environmental awareness fast on the rise, tech giants believe they can help lead such change. But as the world relies more on the internet, we are also relying more on old and dirty energy sources.

## Based on:

Clement, J. (2020, June 4). Global digital population as of April 2020. Statista. Retrieved July 16, 2020, from   https://www.statista .com/statistics/617136/digital-population-worldwide

Elegant, n.X. (2019, September 18). The internet cloud has a dirty secret. Fortune. Retrieved June 10, 2020, from   https://fortune .com/2019/09/18/internet-cloud-server-data-center-energyconsumption-renewable-coal/

These increases in the number of users, the amount of data storage, and the desire for bandwidth-hungry applications like video suggest that energy consumption to drive the internet will continue to increase rapidly over the next decades. Many of the largest tech companies are aggressively pursuing renewable and sustainable energy sources to power their facilities; much of the energy generated within the developing world, however, still comes from cheap energy sources like coal. In 2017, coal provided approximately

Elegant, n.X. (2020, January 9). 'They must scale up:' Greenpeace ranks China's tech giants on renewable energy. Fortune . Retrieved June 10, 2020, from   https://fortune.com/2020/01/09/ greenpeace-china-tech-companies-green-energy-ranking

Fernández Alvarez, C. (2019, december 12). Fading fast in the uS and Europe, coal still reigns in Asia. International Energy Agency. Retrieved June 10, 2020, from   https://www.iea.org/commentaries/ fading-fast-in-the-us-and-europe-coal-still-reigns-in-asia

Livingston, H., Pallas, n., Jones, J., and diu, n.L. (2020, March 5). dirty streaming: The internet's big secret. BBC News. Retrieved June 10, 2020, from   https://www.bbc.com/news/av/stories-51742336/ dirty-streaming-the-internet-s-big-secret advantage, as is the case with Amazon or Dell) to support their business processes; in other words, organizations leave the building of applications to other parties and assume that these applications will work. Given this trend, a solid infrastructure is important, as the infrastructure determines how quickly new systems can be implemented and how well they will function; turning over the responsibility for the lower levels of the infrastructure to other organizations allows a business to focus on developing and implementing those applications that help to gain or sustain competitive advantage. This becomes even more important as any lack of robustness or integration of an organization's infrastructure will be immediately noticed by customers or other stakeholders, potentially leading to loss of business, trust, or goodwill.

## What Is Cloud Computing?

Technological advances such as increasing internet  bandwidth  and  advances  in  virtualization have given rise to cloud computing; the 'cloud' is a metaphor for the internet (see   Figure   3.  21  ). As defined by the National Institute of Standards and Technology (NIST), 'Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services)

## FIGURE 3.21

Processing, storage, and transmission of data taking place in the cloud.

## FIGURE 3.22

Cloud computing uses a utility computing model, allowing companies to pay for computing resources on an as-needed basis.

<!-- image -->

that can be rapidly provisioned and released with minimal management effort or service provider interaction' (Mell &amp; Grance, 2011). Using a utility computing model (i.e., organizations 'renting' resources such as processing, data storage, or networking from an external provider on an as-needed basis and paying only for what is actually used), cloud computing thus helps transform IS infrastructure costs from a capital expenditure to an operational expenditure (Figure 3.22). One prime example of a cloud computing provider is Amazon Web Services; having built an immense infrastructure (in terms of both information technology and logistics) for supporting its online store, Amazon has decided to use these resources to generate additional revenue streams. For example, individuals and organizations can rent storage space on Amazon's Simple Storage Service (S3) or computing time on Amazon's Elastic Compute Cloud (EC2), all on an as-needed basis. The ability to create an entire infrastructure by combining Amazon's various services has facilitated many successful startup companies, such as the social scrapbooking site Pinterest and the community travel marketplace Airbnb. As Airbnb grew in popularity with travelers all over the globe, the company found itself being limited by challenges and constraints imposed by its

<!-- image -->

<!-- image -->

original service provider. Moving to Amazon Web Services allowed Airbnb to quickly obtain 200 servers without needing to negotiate service contracts or commit to minimum usage. Flexibly scaling the infrastructure would have been close to impossible were Airbnb using its own data center because of both the time and the money needed to acquire this number of servers, and at the time, who knew whether Airbnb's business would actually take off? With a traditional in-house infrastructure, Airbnb would have had to add capacity in 'chunks,' leading to either having too many unused resources or not being able to satisfy its users' demand; using a cloud infrastructure, Airbnb can elastically scale the resources to be just above what is needed to keep the users satisfied (Figure 3.23).

CLOUD CHARACTERISTICS. The cloud computing model has several unique and essential characteristics that distinguish cloud computing from an in-house infrastructure and provide various benefits to users (Mell &amp; Grance, 2011). These characteristics are discussed next.

On-Demand Self-Service To allow for most flexibility, users can access cloud resources in a buffet-style fashion on an as-needed basis without the need for lengthy negotiations with the service provider; in many cases, resources in the cloud are accessible by the customer with no need for human interaction with the provider. In the case of Amazon Web Services, a customer needs only a credit card (for billing purposes) and can set up server instances or expand storage space via a web-based control panel. For businesses whose needs may rapidly change, this allows for unprecedented flexibility, as it greatly facilitates scaling the infrastructure up or down as needed and enables organizations to quickly build MVPs or conduct experiments.

Rapid Elasticity Typically, servers and other elements of an IS infrastructure take several weeks to be delivered and days or weeks to be configured (as a company's IS personnel must install and configure system software, databases, and application software, depending on the organization's needs); in contrast, in a cloud environment, computing resources can be scaled up or down almost instantaneously and often automatically, based on user needs. Hence, there is no need to purchase expensive equipment to prepare for an anticipated surge in demand (which ultimately may not materialize) during the holiday season. If, however, the surge in demand does materialize, businesses can access the required resources instantaneously at almost any quantity.

Broad Network Access As cloud services are accessed via the internet, they are accessible from almost anywhere and from almost any web-enabled device. For organizations, this enables real-time management of business processes, as applications hosted in the cloud can be accessed whenever needed, from any location, be it from one's desktop or laptop or using an iPhone, iPad, or Android smartphone app. Thus, knowledge workers can swiftly respond to anything that may require their immediate attention without having to be physically in their office.

Resource Pooling Rather than renting out space or time to each customer on one specific, physical machine, cloud providers manage multiple distributed resources that are dynamically assigned to multiple customers based on their needs. Hence, the customer only rents a resource with no knowledge or control over how it is provided or where it is located. In some cases, however, service providers allow for specifying particular geographic areas of the resources;

## FIGURE 3.23

It is difficult to match demand using an in-house infrastructure; with a cloud infrastructure, resources can be added incrementally, on an as-needed basis.

FIGURE 3.24 Services by IaaS, PaaS, and

SaaS providers.

for example, a California company may want to rent resources located in California (close to its customers) to reduce response latency, or a European company may need to rent storage space on servers located in Europe to comply with data protection directives.

Measured Service Measured service is typically used in a utility computing model, where providers monitor usage and customers pay only for what they use. Different resources can have different types of metering. For example, customers could either be charged on an hourly basis for the use of server instances (the price typically depends on the instance's computing power, memory, and operating system), or be charged based on volume of data stored and/or transferred into or out of the cloud. For customers, the fixed costs associated with the IS infrastructure are thus transformed into variable costs, which are easy to track and monitor.

SERVICE MODELS. As can be seen from the previously mentioned examples, various services are provided in the cloud. Whereas some users require access only to certain software, others want to have more control and be able to run the software of their choice on a server in the cloud (Figure 3.24). Different cloud computing service models (Mell &amp; Grance, 2011) are discussed next.

Infrastructure as a Service In the infrastructure as a service (IaaS) model, only the basic capabilities of processing, storage, and networking are provided. Hence, the customer has the most control over the resources. For example, using Amazon Web Services, customers can choose computing power, memory, operating system, and storage based on individual needs and requirements, thus being able to build (almost) their entire infrastructure in the cloud. Using such infrastructure, Netflix migrated its own IS infrastructure to Amazon Web Services to transcode movies into various formats, power its customer-focused website, and host other mission-critical applications. The IaaS model provides the customer with the greatest flexibility; on the other hand, while the infrastructure is provided, managing software licenses is still the responsibility of the customer, and setup costs are relatively high.

Platform as a Service In the platform as a service (PaaS) model, customers can run their own applications, which are typically designed using tools provided by the service provider. In this model, the user has control over the applications but has limited or no control over the underlying infrastructure. One example is Microsoft's Windows Azure, which acts as a cloud services operating system that customers can use to deploy custom applications. Using this platform, Outback Steakhouse launched a viral marketing campaign when it first introduced its Facebook Fan Page. To support the spikes in demand, Outback developed and deployed an email marketing campaign using Windows Azure. As the underlying computing platform is provided, the customer does not have to worry about purchasing software licenses, for example, for the web servers' operating systems or for database management systems, and the service provider manages the functioning and updating of the platform provided. A new trend is serverless computing. Designed to free users from having to set up virtual machines,

<!-- image -->

serverless computing platforms such as Amazon's AWS Lambda allow for simply running small, specific functions, which can be integrated to develop applications. The service takes care of all management of the underlying platform, enabling continuous scaling, and the user is charged on the basis of usage time.

Software as a Service In the software as a service (SaaS) model, the customer uses only applications provided via a cloud infrastructure. Typically, such applications include web-based email services (e.g., Google's Gmail) and web-based productivity suites (such as Zoho or Google Docs) but also advanced applications such as CRM systems, as provided by Salesforce.com (see Chapter 8). Typically, the customer cares only about the application, with no knowledge or control over the underlying infrastructure and typically has only limited ability to control or configure application-specific settings. Applications under the SaaS model are typically easiest to deploy because the customer does not have to worry about maintaining or updating the software, the underlying platform, or the hardware infrastructure. Some companies have started offering entire solutions as a service, providing not only software, but also other aspects such as expertise.

TYPES OF CLOUDS. Cloud service providers such as Amazon offer what is referred to as a public cloud . Services in a public cloud can be used by any interested party on a pay-per-use basis; hence, they are often used for applications that need rapid scalability (i.e., the ability to adapt to increases or decreases in demand for processing or data storage) or in cases where there is insufficient capital or other resources to build or expand an IS infrastructure. In contrast, a private cloud (or internal cloud) is internal to an organization and can help the organization balance demand and supply of computing resources within the organization; similar to a public cloud, a private cloud provides self-service access to resources, allowing business users to provision resources on-demand using a utility computing model. A private cloud does not free an organization from the issues associated with managing the cloud infrastructure, but it does give the organization a high degree of customizability, flexibility, and control over its data and applications (Figure 3.25).

## Managing the Cloud

Because of its various benefits, cloud computing has gained much popularity, especially among executives who try to harness the potential of scalability and increase the business' agility. However, there are also various issues management should consider when moving infrastructure to the public cloud. The first consideration is which applications, services, or data to move to the cloud. Typically, there is no single cloud computing provider that can meet all needs of an organization. Rather, organizations often have to partner with different service providers, selecting IaaS, PaaS,

<!-- image -->

## FIGURE 3.25

Public clouds versus private clouds.

## FIGURE 3.26

Organizations must consider various issues when managing their cloud infrastructure.

<!-- image -->

and SaaS models based on the business's needs and often combining public and private clouds; as  there  is  not  one  solution  that  fits  all,  organizations  must  carefully  weigh  the  benefits  and downsides of cloud computing. In addition, organizations must carefully consider which cloud services provider to choose. Some of the long-term, strategic issues that management should consider when evaluating different public cloud service providers include availability, reliability, scalability, viability, security, privacy, compliance, diversity of offerings, openness, and, not least, cost (Figure 3.26). These are discussed next.

AVAILABILITY/RELIABILITY. The availability of the service is a primary concern for most organizations. As shown by examples from Google, Amazon, and Microsoft, not even the largest public cloud computing providers are immune from problems, be it hardware failures, programming errors, or some network outage. Organizations thus must evaluate which applications to move to the cloud and how to ensure the availability of cloud-based applications. In addition to examining what the promised uptime of the application/system is, what backups are made to the servers and storage, or whether sufficient bandwidth will be provided to access large amounts of data, organizations must implement their own precautionary measures. As it is often too costly (e.g., in terms of lost business or goodwill) to be affected by negative events, organizations should plan ahead and replicate their cloud-based infrastructure in different locations. Related to this, an important criterion to consider is the provider's support policies. In case something does not work as promised, how will issues be resolved? One of the advantages of cloud computing is self-service, allowing clients to provision resources as needed. At the same time, this can be a potential downside, as there is not always the guarantee of having help available, if needed. Thus, organizations must ensure that acceptable support capabilities and personnel are available, especially for mission-critical applications, to rapidly solve technical issues when they arise.

SCALABILITY. One of the biggest promises of cloud computing is scalability, such that organizations can scale up or down their infrastructure as needed. Yet not every provider will be able to meet every organization's demands. Thus, organizations must carefully evaluate to what extent the provider will be able to meet current and future business needs in terms of data storage, transaction volumes, and so on.

VIABILITY. Another important issue is associated with the viability and stability of the provider in the long run. As an organization moves to a public cloud infrastructure, it puts much data and processing capabilities into the hands of an outside entity. If this outside entity happens to go out of business, this can have many repercussions for the organization, such as costs and efforts involved in setting up a new infrastructure, migrating applications, or transferring the data from the old provider to the new infrastructure.

SECURITY, PRIVACY, AND COMPLIANCE. In addition to concerns related to availability, reliability, scalability, and viability of the vendor, security, privacy, and compliance are critical aspects to consider when deciding which data and applications to move to the cloud and which provider to select. Especially when sensitive data are concerned, organizations must question how secure the data will be from outside intruders, how the privacy of customer data will be protected, and whether the data storage complies with regulations such as the Sarbanes-Oxley Act and the Health Insurance Portability and Accountability Act (HIPAA) and standards such as the Payment Card Industry Data Security Standard. By definition, a public cloud infrastructure is shared among different companies with different applications running on the same hardware; as a result, it is impossible for organizations to know where exactly (physically) the data are located, and thus auditing who has access to the data is extremely difficult, if not impossible. Whereas using

an in-house infrastructure, a company has complete control over its own data, this control is lost in a cloud infrastructure, and organizations have fewer legal rights if their data are stored in the cloud. Similarly, cloud computing providers may be asked to hand over sensitive data stored on their servers to law enforcement, leaving the organization with little control. Especially for industries heavily concerned with privacy and data protection, such as firms in the medical or legal fields, these issues are of critical importance. On the other hand, public cloud computing providers are certainly aware of these issues, and organizations must weigh which applications or data to move to the cloud and which to keep in-house.

Issues such as availability, reliability, and security are normally covered in service-level agreements (SLAs) , which are contracts specifying the level of service provided in terms of performance (e.g., as measured by uptime), warranties, disaster recovery, and so on. A big caveat is that such service-level agreements do not guarantee the availability of resources; rather, they only promise certain service levels and provide for refunds or discounts if these promises are not met and can thus be regarded mostly as a vehicle for resolving conflicts in case of problems.

For businesses, this poses a serious dilemma, as such refunds and discounts normally only cover the costs paid for the service but can never offset the opportunity costs arising from lost business. On the other hand, when evaluating the benefits and drawbacks of moving the infrastructure to the public cloud, organizations also must critically evaluate how far they would be able to maintain certain uptime using an in-house infrastructure and at what costs; often, organizations realize that even though certain SLAs may not be met by the provider, the provider can still offer better uptime than a poorly managed in-house infrastructure. In evaluating their options, organizations often choose a hybrid approach, having certain mission-critical applications in-house while moving other, less demanding applications (in terms of uptime, etc.) to the public cloud.

DIVERSITY OF OFFERINGS. As discussed earlier, there are various providers of cloud computing services, ranging from IaaS to SaaS. As a larger number and diversity of providers is more difficult to manage, many organizations prefer to deal with fewer providers that can meet all needs. Thus, an important question to ask is which provider can offer the services needed both presently and in the future.

OPENNESS. A related question organizations face is the issue of interoperability. Most cloud providers use different infrastructures, different ways to store data, and so on. This, however, makes migrating data between providers extremely difficult and can lead a company to be locked in by a certain provider. In addition to different infrastructures and storage models, existing network bandwidth (and data transmission costs) poses an additional limitation to interoperability, as moving terabytes of data from one provider to another, even using very high-speed networks, can prove extremely time-consuming and expensive (as cloud computing providers often charge for transferring data into or out of their infrastructure).

COSTS. A final issue to consider when moving to a public cloud infrastructure is costs. The utility computing model used by cloud computing providers gives organizations control over the resources used and paid for-the organization only pays for the resources used and can scale the resources up or down when needed. Thus, this provides the organization with much transparency in the cost of the resources. Yet there is considerable disagreement over whether moving to the public cloud is ultimately cheaper than maintaining an in-house infrastructure. For example, the online game developer Zynga moved from a public cloud infrastructure to an in-house private cloud and decided to own, rather than rent, its infrastructure. Comparing the costs of owning versus renting is not an easy feat. Whereas it is easy to calculate the costs per month of a server in Amazon's EC2 cloud, many organizations do not know how much exactly it costs to run a comparable server in an in-house infrastructure, including the costs of the server itself, the fees for software licenses, the electricity, the data center, the staff, and so on. Thus, organizations must carefully balance the benefits and costs of the flexibility and scalability the cloud offers, such as by using a cloud infrastructure only for periods of peak demand; needless to say, this adds another layer of complexity to the IT operations.

In sum, there are various issues to consider when moving to a cloud infrastructure, and each organization must make various informed choices about how to harness the opportunities the cloud offers while minimizing potential drawbacks. In the next section, we will provide a brief discussion of various other applications enabled by the cloud.

## FIGURE 3.27

Using SOA, multiple applications can invoke multiple services.

## Advanced Cloud Applications

Clearly, the cloud offers many ways for businesses to solve their IS infrastructure-related issues. In addition to the different cloud services models, the cloud has enabled other trends, such as using a service-oriented architecture for flexibly deploying new applications, grid computing to help solve large-scale computing problems, content delivery networks for increasing web application performance, and IP convergence for transmitting voice and video communication over the internet. These applications are discussed next.

SERVICE-ORIENTED ARCHITECTURE AND APIs. To achieve greater flexibility and agility, organizations have tried to move away from deploying large, monolithic applications in favor of a service-oriented architecture (SOA) . Using SOA, business processes are broken down into individual components (or services ) that are designed to achieve the desired results for the service consumer (which can either be an application, another service, or a person). To illustrate this concept, think about the next oil change for your car. As you can't be expert in everything, it is probably more effective to have someone change the oil for you. You may take your car to the dealership, you may go to an independent garage or oil change service, or you may ask your friend to do it for you. For you, all that matters is that the service will be provided at the expected level of quality and cost, but you typically do not care if different service providers do things differently or use different tools.

By breaking down business processes into individual services, organizations can more swiftly react to changing business needs. For example, using an SOA approach, multiple services (such as 'check inventory' or 'order supplies') would be orchestrated to handle the individual tasks associated with processing customer orders and could be changed relatively easily if the business process changes.

To facilitate online collaboration with suppliers, business partners, and customers, SOA uses and reuses individual services as 'building blocks' so that systems can be easily built and reconfigured as requirements change. To achieve these benefits, services must follow three main principles:

- ■ Reusability. A service should be usable in many different applications.
- ■ Interoperability. A service should work with any other service.
- ■ Componentization. A service should be simple and modular.

Following these principles, multiple applications can invoke the same services. For example, both an organization's point-of-sale system and e-commerce website could invoke the service 'process credit card,' and a digital dashboard could invoke the services 'display products,' 'display inventory,' and 'display sales' (Figure 3.27). Hosting and deploying such services in the cloud can help in building applications using SOA. In addition, various services an organization may need are available in the cloud, eliminating the need to 'reinvent the wheel.' However,

<!-- image -->

<!-- image -->

whereas an SOA approach appears to be appealing for many companies, it requires tremendous effort and expertise to plan the architecture, select the right services from hundreds or thousands of available services, and orchestrate and deploy the services. Hence, while an SOA approach helps to increase flexibility, the integration of various services can be extremely complex and can be well beyond the means of small enterprises. Microservices, typically connected via APIs, take this a step further, by separating services into smaller units, each of which only addresses one well-defined service, allowing to reduce interdependencies.

GRID COMPUTING. Businesses and public organizations heavily involved in research and development face an ever-increasing need for computing performance. For example, auto manufacturers, such as the GM German subsidiary Opel or Japanese Toyota, use large supercomputers to simulate automobile crashes and to evaluate design changes for vibrations and wind noise. Research facilities such as the Oak Ridge National Laboratory use supercomputers to model neutron transport in nuclear reactors or to study climate change scenarios (Figure 3.28), while others simulate earthquakes using supercomputers; such research sites have a tremendously complex hardware infrastructure.

Although today's supercomputers have immense computing power, some tasks are even beyond the capacity of a supercomputer. Indeed, some complex simulations can take a year or longer to calculate even on a supercomputer. Sometimes an organization or a research facility would have the need for a supercomputer but may not be able to afford one because of the extremely high cost. For example, the fastest supercomputers can cost more than US$200 million, and this does not represent the 'total cost of ownership,' which also includes all the other related costs for making the system operational (e.g., personnel, facilities, storage, software, and so on; see Chapter 9). Additionally, the organization may not be able to justify the costs because the supercomputer may be needed only occasionally to solve a few complex problems. In these situations, organizations either have had to rent time on a supercomputer or have decided simply not to solve the problem.

One way of overcoming cost or use limitations is to utilize grid computing . Grid computing refers to combining the computing power of a large number of smaller, independent, networked computers (often regular desktop PCs) into a cohesive system to solve problems that only supercomputers were previously capable of solving. Similar to cloud computing, grid computing makes use of distributed resources; however, in contrast to cloud computing, the resources in a grid are typically applied to a single large problem. To make grid computing work, large computing tasks are broken into small chunks, which can then be completed by individual computers (Figure 3.29).

However, as you can imagine, grid computing poses a number of demands in terms of the underlying network infrastructure or the software managing the distribution of the tasks. Further, the slowest computer often creates a bottleneck, thus slowing down the entire grid.

## FIGURE 3.28

The Summit supercomputer can perform more than 200,000 trillion calculations per second. Source: Courtesy of oak Ridge national Laboratory, u.S. dept. of Energy.

## FIGURE   3.   29

Grid computing: Computers located around the world work on parts of a large, complex problem.

<!-- image -->

A dedicated grid , consisting of a large number of homogeneous computers (and not relying on underutilized resources), can help overcome these problems. A dedicated grid is easier to set up and manage and, for many companies, much more cost effective than purchasing a supercomputer.

<!-- image -->

## SECURITY MATTERS

## Car Hacking

The thought of riding down the highway in an automobile or bus and having the driver lose control because a malicious hacker has embedded malware into one of the vehicle's onboard computers is frightening. In many high-visibility demonstrations in a variety of magazines and news programs, hackers (or maybe it is better to call them researchers) have shown how they can break into many of these onboard systems.

Many potential onboard systems are vulnerable to hacking. Modern vehicles have a number of control unitsessentially small computers-to operate and integrate a variety of systems, including the engine and transmission, airbags, steering and braking, remote keyless entry, and many others. Each of these systems is coupled together through a maze of networks. Modern vehicles also contain Bluetooth so the driver can connect a smartphone for handsfree mobile phone calls and even Wi-Fi hotspots to provide connectivity for gadgets, entertainment, and passengers. There is a tremendous amount of programming code in modern vehicles, and most of this code is from a broad range of vendors, making it virtually impossible for vehicle manufacturers to understand all potential vulnerabilities. Each of these systems has the potential to be exploited by hackers if design or security flaws are not identified.

A successful break-in typically isn't easy, however, often requiring several researchers several months to figure out. Because of this, some view this vulnerability as more hype than reality, suggesting that hacking into such onboard systems should not be viewed as being a huge safety or security concern. The truth is likely somewhere in the middle between hype and reality. While it may take a particular team a long time to figure out a particular hack into an onboard system, others can learn from these successful efforts to greatly shorten the learning curve. To address this, both technology and vehicle component vendors are working together to standardize approaches, share information, and make supply chains more secure to prevent tampering or counterfeit parts entering a vehicle. At the same time, manufacturers must also learn about vulnerabilities so that any security flaws can be quickly repaired.

## Based on:

Blanco, S. (2020, January 12). State of the anti-car-hacking art from new companies trying to protect your data. Car and Driver. Retrieved June 10, 2020, from   https://www.caranddriver.com/news/ a30482592/car-hacking-prevention-ces

Hyatt,  K.  (2019,  december  18).  new  study  shows  just  how bad vehicle hacking has gotten. CNET Road/Show. Retrieved June  10,  2020,  from    https://www.cnet.com/roadshow/ news/2019-automotive-cyber-hack-security-study-upstream vardi,  y.  (2019,  december  22).  What  to  expect  from  car hackers  in  2020  and  beyond. Venture  Beat. Retrieved June  10,  2020,  from    https://venturebeat.com/2019/12/22/ what-to-expect-from-car-hackers-in-2020-and-beyond

CONTENT DELIVERY NETWORKS AND EDGE COMPUTING. Another trend in IS infrastructure management is the use of content delivery networks to increase performance of websites. Typically, the larger the geographical distance between a user and the web server hosting certain content, the longer it takes to transmit the content; this can be especially noticeable for content such as streaming media but also for other content presented on a web page. Content delivery networks help reduce this latency by providing a network of servers in various geographical locations, which store copies of particular websites. If a user in a particular geographic location requests a certain web page, the content delivery server closest to the user's location delivers the content, significantly speeding up the delivery of the content (Figure 3.30), a process that is normally unnoticed by the user. This process not only saves valuable resources such as bandwidth but also offers superior performance that would otherwise be too expensive for organizations to offer. Content delivery networks have evolved into edge computing , where not only data storage but also processing is moving away from a centralized location to the 'edges' of a network, which allows for minimizing latency. With increasing digital density, reducing latency is becoming crucial for a growing number of applications. For example, higher latency reduces the usability of Amazon's home assistant Alexa, makes automated stock trading or the operation of autonomous vehicles nearly impossible, and can result in life or death of a patient wearing an internet-connected EKG vest monitoring his vital functions. In addition to reducing latency, with an increasing number of connected devices, other key benefits of edge computing include reduced network traffic and lower costs.

CONVERGENCE OF COMPUTING AND TELECOMMUNICATIONS. Today, much of an organization's communication and collaboration needs are supported by internet technologies; for example, texting and email have become the communications methods of choice for many people. However, for some topics, other forms of communication are more suited, so managers turn to the telephone, instant messaging, meetings, or videoconferences. The growing convergence of computing and telecommunications can help satisfy such diverse communication and collaboration needs. The computing industry is experiencing an ever-increasing convergence of functionality of various devices. Whereas just a few years ago a cell phone was just capable of making phone calls and people used personal digital assistants to support mobile computing needs, such devices are now converging such that the boundaries between devices are becoming increasingly blurred. Today, smartphones, such as the iPhone 12 or Samsung's Galaxy S20, offer a variety of different functionalities-formerly often available only on separate dedicated devices-to address differing needs of knowledge workers and consumers alike (e.g., phone, email, web browser, navigation system, camera, music player, and so on).

<!-- image -->

## FIGURE 3.30

Content delivery networks store copies of content closer to the end user.

## FIGURE 3.31

IP convergence allows various devices to communicate using IP technologies.

<!-- image -->

In addition to a convergence of capabilities of devices, there is also increasing convergence within the underlying infrastructures. For example, in the past, the backbone networks for the telephone and internet were distinct. Today, increasingly, voice and data traffic share a common network infrastructure. IP convergence , or the use of the internet protocol (IP) for transporting voice, video, fax, and data traffic, has allowed enterprises to make use of new forms of communication and collaboration (e.g., instant messaging and online whiteboard collaboration) as well as traditional forms of communication (such as phone and fax) at much lower costs (Figure 3.31). In the following sections, we discuss two uses of IP for communication: voice over IP and videoconferencing over IP .

Voice over IP Voice over IP (VoIP) (or  IP  telephony) refers to the use of internet technologies for placing telephone calls. Whereas just a few years ago the quality of VoIP calls was substandard, recent technological advances now allow the quality of calls to equal or even surpass the quality of traditional calls over (wired) telephone lines. In addition to the quality, V oIP offers other benefits; for example, users can receive calls from almost anywhere they connect to the internet. In other words, knowledge workers are not bound to their desk to receive VoIP calls; instead, using IP routing, their telephone number 'follows' them to wherever they connect to the internet. For example, Christoph, who lives in Barcelona, has VoIP telephone numbers in the United States and Germany so that friends and family members living in these countries can call him at local rates. Organizations can also benefit from tremendous cost savings, as often there is little cost incurred over and above the costs for a broadband internet connection (e.g., VoIP software such as Skype allows users to make Skype-to-Skype calls for free).

Videoconferencing over IP In addition to voice communications, IP can also be used to transmit video data. Traditionally, videoconferences were held either via traditional phone lines, which were not made to handle the transfer of data needed for high-quality videoconferencing, or via dedicated digital lines, which was a very costly option. Similar to VoIP, the internet also helped to significantly reduce costs and enhance the versatility of videoconferences by enabling videoconferencing over IP .

For some videoconferences, desktop videoconferencing equipment (consisting of a webcam, a microphone, speakers, and software such as Google Hangouts or Skype) may be sufficient; for others, higher-end equipment may be needed. Such infrastructure can include specific videoconferencing hardware, or it can be a dedicated virtual meeting room featuring life-sized

<!-- image -->

images allowing people from across the globe to meet as if they were sitting in the same room (Figure 3.32). We discuss videoconferencing in more detail in Chapter 5, 'Enhancing Organizational Communication and Collaboration Using Social Media.'

## Green Computing

Fueled by the rapid advances of developing nations, the world has seen a tremendous increase in demand for and cost of energy. For organizations having hundreds or thousands of computers, rising energy costs are becoming a major issue. Further, organizations are being increasingly scrutinized for their contribution to societal issues such as climate change (see Chapter 1); more and more organizations are trying to portray a 'greener' image when it comes to the use of energy and natural resources, as company executives have realized that they cannot afford the consequences of inaction on the company's reputation. As 'green' efforts can save money on energy and water use, waste disposal, and carbon taxes and can be subsidized by grants, rebates, or free technical advice, they can also have positive impacts on a company's bottom line.

Green computing , or attempts to use computing resources more efficiently to reduce environmental impacts, as well as the use of information systems to reduce negative environmental impacts, can contribute to these efforts by helping to use computers more efficiently, doing the same (or more) with less. For example, organizations can save large amounts of money for power and cooling by using virtualization to replace hundreds of individual servers with just a few powerful mainframe computers. As studies have shown, computing resources in organizations are often very much underutilized, and using virtualization can help lower an organization's energy bill and carbon footprint. Similarly, cloud computing has been argued to contribute to reduced energy consumption, as the service provider's infrastructure is shared by many users. Installing sophisticated power management software on individual desktops can save much energy that is wasted by leaving computers idling or on standby overnight. Further, discouraging employees from printing out emails or business documents can help to reduce the waste of paper-an average office worker prints more than a tree's worth of paper each year.

A related issue is the retiring of obsolete hardware. Today, companies cannot just send retired equipment to a landfill. Rather, companies and individuals must evaluate how to best dispose of unwanted computers, monitors, and parts. Whereas the first step is to make the decision when to retire equipment, the next steps are equally important. Needless to say, it must be ensured that old computers are wiped of all user data. Many third-party outsourcers ('IT asset disposition' vendors) offer services including wiping all computer hard drives and either refurbishing and selling usable equipment or dismantling the components to recycle valuable raw materials and properly dispose of hazardous waste.

## FIGURE 3.32

Videoconferencing can help organizations and individuals reduce their need for in-person meetings.

Source: dotshock/Shutterstock.

<!-- image -->

## INDUSTRY ANALYSIS

## Movie Industry

do you remember the original Star Wars movies or movies such as King Kong (1976) or Godzilla (1954)? Compare these to recent box office hits such as Star Wars IX: The Rise of Skywalker (2019 ), Deadpool 2 (2018), or animated movies such as Trolls World Tour (2020). With each new generation of movies, a tremendous increase in computing power can also be leveraged, enabling film studios such as dreamworks and universal Studios or special effects studios such as Weta digital and Pixar to create hitherto unimaginable quality computer-generated imagery (CGI, also known as computer graphics).

As for major studios, rapidly evolving digital technology (specifically, recording hardware and sophisticated yet easy-to-use digital editing software) has opened vast opportunities for independent filmmakers who are producing studioquality films without having to rely on expensive lighting, film development, and postproduction facilities. Thus, people who could never afford all the necessary equipment can now produce movies digitally. Further, digital cameras and projectors and advances in software have made the transition from celluloid to digital more attainable for filmmakers who until recently used traditional technology. And it is not just the little independent filmmakers embracing the digital trend. Today, most films made by large studios such as Paramount Studios and Warner Brothers are shot and edited using 100 percent digital formats. Another big innovation is the use of drones for recording the action. drones are a very low-cost alternative to expensive helicopters and have the added benefit of being able to go places that humans or helicopters simply cannot, due to size or safety constraints. This is a particular advantage for independently developed movies that don't have the budget of major blockbusters as well as for sports reporting.

The impact of technology on the movie industry does not stop with movie production. Many movie theaters across the world have shifted to digital projection technologies, reducing the need for duplicating and shipping large reels of film and reducing distribution costs by up to 90 percent while speeding up the time from the studio to the theater.

Rather than on reels of film (that are susceptible to outof-focus projection, scratches, or 'pops'), the movies are stored on central servers, from which they are accessed and downloaded via the internet by individual theaters. Theater owners can much more swiftly react to fluctuating demand and easily show movies on more than one screen in case of high demand. In addition, the CovId-19 pandemic brought us the first video on demand blockbuster in Trolls World Tour . Clearly, the use of information systems has tremendously changed the movie industry.

## Questions

1. Can digital technologies help movie theaters compete with the increasing trend toward more sophisticated home theaters? If so, how?
2. What are the ethical issues associated with special effects becoming more and more realistic with the help of digital technologies?
3. From the perspective of movie studios and theaters, list the pros and cons of using digital distribution technologies.

Based on:

Captain,  S.  (2020,  April  30).  Hollywood  drone  operators  win  recognition  as  photographers. DroneDJ. Retrieved J u n e   10,  2020,  from    https://dronedj.com/2020/04/30/ hollywood-drone-operators-win-recognition-as-photographers digital cinematography. (2020, April 12). In Wikipedia, The Free Encyclopedia . Retrieved June 10, 2020, from   https://en.wikipedia .org/w/index.php?title=digital\_cinematography&amp;oldid=950469569

Serafim, K. (2020, January 24). CES digital Hollywood - AR/vR/ XR: Top technology and entertainment companies - Key takeaways. Verizon Ventures. Retrieved June 10, 2020, from   http:// www.verizonventures.com/blog/2020/1/ces-digital-hollywood%E2%80%93-arvrxr-top-technology-and-entertainmentcompanies-%E2%80%93-key-takeaways

Wilkinson, A. (2020, January 29). Hollywood is replacing artists with AI. Its future is bleak. Vox. Retrieved June 10, 2020, from    https://www.vox.com/culture/2020/1/29/21058521/ hollywood-ai-deepfake-black-mirror-gemini-irishman-cinelytic

## Key Points Review

1. Describe how changes in businesses' competitive landscape influence changing IS infrastructure needs. Organizations are facing continuously changing business environments, and quickly adapting to a constantly changing competitive environment necessitates that businesses are increasingly flexible and agile. Modern organizations use various applications and databases to support their business processes; these applications and databases rely on a solid underlying IS infrastructure consisting of hardware, system software, storage, networking, and data.
2. Describe the essential components of an organization's IS infrastructure. Organizations use various types of IS hardware to meet their diverse computing needs. The most prominent type of system software, the operating system, coordinates the interaction between hardware devices, peripherals, application software, and users. Further, organizations need to store massive amounts of data for operational, backup, and archival purposes. Networking is one of the reasons why information systems have become so powerful and important to modern organizations. Finally, organizations use data centers to house the different infrastructure components to ensure security and availability.
3. Discuss managerial issues associated with managing an organization's IS infrastructure. Radical advances in information technology have opened many opportunities for organizations but have also brought about challenges. Advances in hardware have enabled advances in software. Hardware and software obsolescence, faster IT cycles, and consumerization present issues such as when and how to upgrade the
4. current infrastructure. Further, organizations' storage needs are growing at an ever-increasing pace, and organizations also must deal with fluctuations in demand for computing power while often being unable to quickly scale the IS infrastructure accordingly. The increasing need for both computing power and storage fuels an increasing demand for energy, which can affect a company's image as well as its bottom line. Finally, the organizations need to be increasingly agile to survive in today's fast-paced competitive environment.
4. Describe cloud computing and other current trends that can help an organization address IS infrastructure-related challenges. Cloud computing uses a utility computing business model where customers can draw on a variety of computing resources that can be accessed on demand with minimal human interaction. Characteristics of cloud computing include on-demand self-service, rapid elasticity, broad network access, resource pooling, and measured service. Typical cloud computing service models are infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS). When considering the move to a public cloud-based infrastructure, organizations must weigh issues such as availability, reliability, scalability, viability, security, privacy, compliance, openness, diversity of offerings, and, not least, cost. Other applications in the cloud include SOA, grid computing, content delivery networks, voice over IP, and videoconferencing over IP. Finally, a recent trend is green computing, as companies realize potential cost savings and a positive effect on the company's image by implementing ways to reduce energy consumption and waste.

## Key Terms

- public cloud 151

radio frequency identification

(RFID) 130

RFID tag 130

scalability 151

server 128

service

154

service-level agreement (SLA) 153

service-oriented architecture

(SOA) 154

software as a service (SaaS) 151

supercomputer 128

system software 130

thin client 135

top-level domain

137

Transmission Control Protocol/Internet

Protocol (TCP/IP) 138

transmission media 134

Uniform Resource Locator (URL) 137

utility computing

148

videoconferencing over IP

158

voice over IP (VoIP) 158

web browser 136

web page

136

web server 136

website 136

wide area network 136

Wi-Fi (wireless fidelity)

network 136

wireless local area network

(WLAN) 136

workstation 129

World Wide Web 136

## Review Questions

- 3-1. How do applications support organizational business processes?
- 3-2. How do databases support organizational business processes?
- 3-3. Describe the key functions of system software.
- 3-4. For which purposes are data stored in organizations?
- 3-5. What are the distinguishing characteristics of different storage media?
- 3-6. How does computer networking work?
- 3-7. What are the major types of networks?
- 3-8. What is the World Wide Web, and what is its relationship to the internet?

## Self-Study Questions

3-15.

All of the following are examples of infrastructure

components except \_\_\_\_\_\_\_\_\_\_.

- A. hardware

- B. system software

- C. data centers

- D. applications

- 3-16. Which of the following is not a consequence of lack of availability, performance, or security?

- A. loss of managerial oversight

- B. loss of business

- C. loss of trust

- D. loss of goodwill

- 3-17. Engineering drawings are typically prepared using

\_\_\_\_\_\_\_\_\_\_.

A. mainframes

- B. servers

- C. personal computers

- D. workstations

3-18. Magnetic tape is typically used for \_\_\_\_\_\_\_\_\_\_.

- A. storing operational data

- B. backing up critical data

- 3-9. What are URLs, and why are they important to the World Wide Web?

- 3-10. What are the problems associated with software obsolescence?

- 3-11. Describe the characteristics of the cloud comput- ing model.

- 3-12. Define grid computing and describe its advan- tages and disadvantages.

- 3-13. Describe what is meant by the term IP convergence .

- 3-14. Describe why green computing has become so important to modern organizations.

C. maintaining customer records

D. archiving data

3-19.

Which of the following is the protocol of the

internet?

A. URL

B. HTML

C. TCP/IP

D. ARPA

3-20.

All of the following are correct domain suffixes

except \_\_\_\_\_\_\_\_\_\_.

A. .edu -educational institutions

- B. .gov-U.S. government

- C. .neo-network organizations

- D. .com-commercial businesses

- 3-21. The ability to adapt to increases or decreases in demand for processing or storage is referred to as

\_\_\_\_\_\_\_\_\_\_.

- A. adaptability

- B. flexibility

- C. scalability

- D. agility

- 3-22.

3-23.

- In cloud computing, services are typically offered using \_\_\_\_\_\_\_\_\_\_.
- A. private clouds
- B. heterogeneous grids
- C. a utility computing model
- D. edge computing

For the most flexibility in the use of computing resources, companies choose a(n) \_\_\_\_\_\_\_\_\_\_

provider.

- A. utility computing
- B. software as a service

## Problems and Exercises

- 3-25. Match the following terms with the appropriate definitions:
- i.  Utility computing
- ii.  Service-level agreement
- iii.  System software
- iv.  Software as a service
- v.  Voice over IP
- vi.  Cloud computing
- vii.  Bandwidth
- viii.  Server
- ix.  Planned obsolescence
- x.  Scalability
- a.  The incorporation of a life span into the design of a product
- b.  The use of internet technology for placing telephone calls
- c.  A cloud computing model in which the customer uses an application provided via a cloud infrastructure
- d.  A model for enabling convenient, on-demand network access to a shared pool of configurable computing resources
- e.  Any computer on a network that makes access to files, printing, communications, and other services available to users of the network
- f.  The transmission capacity of a computer or communications channel
- g.  A business model where computing resources are rented on an as-needed basis
- h.  Contracts specifying the level of service provided in terms of performance, warranties, disaster recovery, and so on
- i.  The collection of programs that control the basic operations of computer hardware
- j.  The ability to adapt to increases or decreases in demand for processing or data storage
- 3-26. Take a look at the website of an online social network. Which pieces of information are likely coming from information stored in databases?
- 3-27. Which applications are mission-critical for an online retailer? For a bank? Justify your assessment.

## 3-24.

- C. platform as a service
- D. infrastructure as a service
3. Large-scale computing problems can be solved using \_\_\_\_\_\_\_\_\_\_ computing.

A. grid

B. utility

C. cloud

- D. edge

Answers are on page 165.

- 3-28. How often do you update software on your computer? Do newer versions offer more features, better performance, or both? Give examples of updates that did not bring about the expected results.
- 3-29. Interview an IS professional about the different types of computers used within the organization. What types are most important? Why?
- 3-30. Search the web for information about hard drives, tape drives, and cloud backup services. What would you use for backing up your data? Why?
- 3-31. Scan the popular press and/or the web for clues concerning emerging technologies for computer networking. This may include new uses for current technologies or new technologies altogether. Discuss as a group the 'hot' issues. Do you feel they will become a reality in the near future? Why or why not? Prepare a 10-minute presentation of your findings to be given to the class.
- 3-32. Choose a popular smartphone or tablet and compare and contrast the newest model and an older, heavily discounted one. What are the benefits and drawbacks of choosing one over the other?
- 3-33. How does hardware and software obsolescence affect your life? Give examples of experiences with outdated hardware or software. How did you deal with these situations?
- 3-34. Compare your computer's energy use with that of other appliances. What is the energy primarily used for? How much energy seems wasted?
- 3-35. Imagine you want to launch a startup for a music streaming service, and research cloud service providers for your infrastructure needs. What options do you have? Which one would you choose and why?
- 3-36. Try out a cloud-based provider of presentation software (such as www.prezi.com). How does the service compare to locally installed software? Would you switch to the cloud-based provider? Why or why not?
- 3-37. Search the web for services allowing you to store and manage your medical information online. Would you entrust such services with your medical information? Why or why not?

- 3-  38. Research the web for service-level agreements of two different providers of cloud services and compare these based on availability, security, and privacy. What do the providers promise in case the promised levels of service are not delivered? Is the customer

## Application Exercises

Note: The existing data files referenced in these exercises are available on http://www.pearsonglobaleditions.com/  .

<!-- image -->

## Spreadsheet Application: Tracking FrequentFlier Mileage

3-  40.

You have recently landed a part-time job as a business analyst for Campus Travel. In your first meeting, the operations manager learned that you are taking an introductory MIS class. As the manager is not very proficient in using office software tools, he is doing all frequent-flier mileage in two separate Excel workbooks. One is the customer's contact information, and the second is the miles flown. Being familiar with the possibilities of spreadsheet applications, you suggest setting up one workbook to handle both functions. To complete this, you must do the following:

- ■ Open the spreadsheet frequentflier2.csv. You will see a tab for customers and a tab labeled 'miles flown.'
- ■ Use the vlookup function to enter the miles flown column by looking up the frequent-flier number. (Hint: If done correctly with absolute references, you should be able to enter the vlookup formula in the first cell in the 'miles flown' column and copy it down for all the cells.)
- ■ Use conditional formatting to highlight all frequent fliers who have less than 4,000 total miles.
- ■ Finally, sort the frequent fliers by total miles in descending order.

## Team Work Exercise

<!-- image -->

## Net Stats: Mobile Broadband Is Growing Substantially

An internet broadband connection can be delivered through either  a  fixed  line  or  a  mobile  connection.  Mobile  broadband  connections  make  it  easy  to  connect  mobile  devices such  as  smartphones,  laptops,  and  tablets  to  the  internet on-the-go via 4G or 5G networks. Mobile broadband has been growing  substantially  in  recent  years,  in  line  with  the  vast worldwide mobile phone adoption. In  2020,  the  number  of mobile broadband subscriptions worldwide reached about 8 billion and this is projected to increase further in the coming years. China and India from the Asia Pacific account for the highest subscription globally while the Americas and Europe have the highest number of mobile broadband subscriptions per 100 inhabitants. Besides, there is significant progress in

- compensated for any data losses due to the provider's fault?
- 3-  39. Compare and contrast major VoIP providers focusing on end consumers. How do the services differ? Which service would you choose? Why?

<!-- image -->

## Database Application: Building a Knowledge Database

3-  41.

- Campus Travel seems to be growing quite rapidly. Now it has franchises in three different states, totaling 16 locations. As the company has grown tremendously over the past few years, it has become increasingly difficult to keep track of the areas of expertise of each travel consultant; often, consultants waste valuable time trying to find out who in the company possesses the knowledge about a particular region. Impressed with your skills, the general manager of Campus Travel has asked you to add, modify, and delete the following records from its employee database:
- ■ Open employeedata.mdb.
- ■ Select the 'employee' tab.
- ■ Add the following records:
- a.    Eric Tang, Spokane Office, Expert in Southwest, Phone (509) 555-2311
- b.    Janna Connell, Spokane Office, Expert in Delta, Phone (509) 555-1144
- ■ Delete the following record:
- a.    Carl Looney from the Pullman office
- ■ Modify the following:
- a.    Change Frank Herman from the Pullman office to the Spokane office
- b.    Change Ramon Sanchez's home number to (208) 549-2544

network and broadband access technologies. Long-term evolution (LTE) 4G networks are now widely available in many countries  while  5G-the  next  generation  of  mobile  broadband technology-is being deployed across the world. It is estimated that by 2025, there will be about 745 million 5G connections across North America and Europe, which is a significant increase from just 22 million in 2020.

## Questions and Exercises

- 3-  42. Search the web for mobile broadband pricing models in your home country and three other countries.
- 3-  43. As a team, interpret the findings. What is striking/ interesting about these findings? What may be the reason for differences in the pricing models?

<!-- image -->

- 3-44. Discuss how these numbers may look in 5 years and 10 years. Will a particular pricing model become more prevalent than the others? Why or why not?
- 3-45. Using your spreadsheet software of choice, create a graph/figure that effectively visualizes the statistics/ changes you consider most important.

Based on:

ITU  (2021). Itu.int .  Statistics.  Retrieved  December  12,  2021,  from  https:// www.itu.int/en/ITU-D/Statistics/Pages/stat/default.aspx

Statista.  (2021). Statista .  Mobile  Broadband-Statistics  &amp;  Facts.  Retrieved December 2, 2021, from https://www.statista.com/topics/1311/mobilebroadband-statistics-and-facts/#dossierKeyfigures

## Answers to the Self-Study Questions

| 3-15. D, p. 123   | 3-16. A, p. 125   | 3-17. D, p. 129   | 3-18. C, p. 133   | 3-19. C, p. 138   |
|-------------------|-------------------|-------------------|-------------------|-------------------|
| 3-20. C, p. 137   | 3-21. C, p. 151   | 3-22. C, p. 148   | 3-23 D, p. 150    | 3-24. A, p. 155   |

## CASE 1 Singaporean Bank DBS Goes Digital

DBS Bank Limited (DBS) is a leading financial services group in Asia. Headquartered and registered in Singapore since 1968, DBS provides wealth management, consumer banking, and institutional banking services. The bank's capital standing, as well as 'AA-' and 'Aa1' credit ratings (these ratings indicate the risk of the institution defaulting on its financial obligations), is one of the highest in the Asia Pacific.

Jeff do? (The reference is, of course, to Jeff Bezos, the founder of Amazon).

In 2016, it had more than 280 branches, 200,000 institutional customers, 6 million retail  customers,  and  more  than  22,000 employees across 18 distinct markets. But since then, headed by the charismatic CEO Piyush Gupta, it has continued to grow and acquire other banks. In 2020, it took over the Lakshmi Vilas Bank, an Indian private sector bank, and entered into an agreement to acquire a stake in the Chinese Shenzen Rural Commerical Bank. In the third quarter of 2021, DBS recorded a net profit of S$1.7 billion (which is US$1.26 billion). In 2021, Euromoney, a leading publication in the field of banking, chose DBS both as the best bank in the world and the best digital bank. It was the first time that both titles were given to the same institution.

DBS is at the frontline of digital technology leveraging. The story goes that CEO Piyush Gupta had a meeting with Chinese businessman Jack Ma in 2014. The meeting took just about an hour, but it changed Gupta's perspective on banking completely. Gupta realized that businessmen like Ma (who was then the CEO of Alibaba) were completely undermining the traditional way of banking based on physical branches, where customers come in person for their transactions. Gupta decided to 'go digital.' One of the mantras of this revolution was that employees of DBS were encouraged to continually ask the question: What would

As a part of that revolution, DBS has always been willing to experiment. In 2017, it started its application programming interface (API) developer platform. These APIs, to put it simply, allow two applications to talk to each other. They are often compared to waiters who are the line of communication in a restaurant between the customer and the kitchen and bring requests from one side to the other. As a result of the APIs, it is easier for many systems to establish a link with DBS, which may make things easier for customers. Thus, it has become easier to get a car loan while buying a car as there is a digital link to the DBS bank. Also, the DBS PayLah! API can be used by customers for a cashless payment of home deliveries by McDonald's. (Needless to say, this option also has an advantage for McDonald's: as less cash is being used, mugging deliverers becomes pointless.)

Over the years, DBS has had the objective of making banking 'joyful.' Going digital was meant to be an exciting journey of discovery.  In  August  2021,  a  digital exchange system became operational. Within two months, the Bank reported that 600 million SGD had been linked up to the exchange. DBS also announced its plans to create a global carbon exchange in 2021. This exchange, which DBS created in cooperation with, amongst others, Standard Chartered from the United Kingdom, will allow companies that are unable in the short run to make their production 'greener,' to buy carbon credits.

Revolutionary steps taken earlier by the Bank include, amongst other things, using Amazon Web Services (AWS) for DBS' Treasury and Markets (T&amp;M) business, whose pricing and valuing financial instruments demand power-hungry computing.

Prior to working with AWS, DBS performed a comprehensive evaluation and a proof-ofconcept. This was to ensure that their cloud implementation met the standards of the Monetary Authority of Singapore's Technology Risk Management guidelines. The bank also further established technology standards, internal approval toll gates, and data encryption standards regarding its cloud implementation.

DBS was also the first bank in Singapore to utilize cloud-based productivity technology like Office 365, which allows employees to seamlessly access their work even outside the office. The imperative was to meet the service levels offered by smaller, more nimble financial  technology  companies;  thus,  DBS equipped its employees with a set of productivity tools that allow them to handle customers' requests more swiftly and efficiently.

All of these innovations show how DBS has always been willing to take risks and learn from their successes and failures in recent years. From this perspective, the Bank looks more like a technological startup than a well-established bank, burdened by many years of history and bureaucratic routine. The willingness of CEO Gupta to learn became very clear when he publicly declared several years ago that simply going digital was not enough. Commenting on the expansion of the bank in countries like Indonesia, the CEO noted that going digital was a great way to attract huge numbers of customers. However, finding customers that generated profits for the bank was something different, he said. (Even at DBS, risk-taking is only sustainable when it generates profits!) DBS has come a long way since Gupta met Jack Ma in 2014. Apart from embracing the opportunities of the new digital era, it has also maintained the culture of a start-up, willing to learn and experiment.

## Questions

- 3-46. Indicate the importance of APIs. What have been the advantages of DBS in creating a developer platform?
- 3-47. Explain what it means to think 'outside of the box' in the context of DBS.
- 3-48. How well is DBS prepared for the future?

Roy Choudhury, S. (2021, May 21). A new global carbon exchange will be launched in Singapore this year. CNBC. Retrieved December 3, 2021, from https://www.cnbc.com/2021/05/21/a-new-global-carbon-exchange-willbe-launched-in-singapore-this-year.html?\_\_source=iosappshare%7Ccom. yahoo.Aerogram.ShareExtension

DBS Bank Ltd. DBS: World's best yet again. Dbs.com . Retrieved February 12, 2022, from dbs.com https://www.dbs.com/about-us/who-we-are/awardsaccolades/a-world-first/euromoney-awards-for-excellence?pid=sg-grouppweb-homepage-hero-world-best-yet-again

Hubbis (2021, November 12). DBS Digital Exchange sees growing business momentum. Hubbis . Retrieved December 3, 2021, from https://www.hubbis. com/news/dbs-digital-exchange-sees-growing-business-momentum

## CASE 2 The Dark Web

Most people don't think too much about the web as long as they are able to visit their favorite websites. Popular websites like nytimes.com reside on what is called the surface webmeaning that they display content that a search engine like Bing, DuckDuckGo, or Google can find when you are searching the web. In addition to the surface web, there is a vast amount of non-indexed content that cannot be found with a normal search engine. This non-indexed content is collectively referred to as the deep web . The deep web is many times larger than the surface web. It has been suggested that the internet can be visualized as a giant iceberg of information, with the content of the surface web being relatively smaller and visible and the deep web having a massive amount of content that is unseen by search engines and is typically more difficult to find and navigate.

only available to those authorized by the owner of the system to view or access.

The deep web contains a variety of content, both lawful and unlawful. Lawful content that resides on the deep web includes corporate and academic databases that cannot be found with a search engine but can be viewed with a normal browser. The deep web also houses content from mainstream websites, like Facebook posts that are only visible to a poster's friends or transaction data that you provide to Amazon when placing an order. All of this lawful content resides on the deep web, and much of it is

Based on:

API University. What are APIs and how do they work? Programmableweb .com . Retrieved February 10, 2022, from https://www.programmableweb .com/api-university/what-are-apis-and-how-do-they-work

McKinsey (2021, October 5). From tech tool to business asset: how banks are using B2B APIs to fuel growth. McKinsey &amp; Company . Retrieved February 12, 2022, from https://www.mckinsey.com/industries/financial-services/ our-insights/from-tech-tool-to-business-asset-how-banks-are-using-b2bapis-to-fuel-growth

Rao, V. (2021, November 15). How DBS became the 'World's Best Bank'. INSEAD Knowledge . Retrieved December 2, 2021, from https://knowledge. insead.edu/blog/insead-blog/how-dbs-became-the-worlds-best-bank-17671

Wright, C. (2021, September 10). The world's best bank 2021: How DBS turned a crisis into an opportunity. Euromoney . Retrieved December 3, 2021, from https:// www.euromoney.com/article/28ten5exmatvsk8bunapt/awards/awards-forexcellence/the-worlds-best-bank-2021-how-dbs-turned-a-crisis-into-an-opportunity

Edward Snowden, who used it to evade NSA watchdogs.

There is also a vast amount of unlawful content on the deep web, and this content is referred to as the dark web. Interest in the dark web has been on the rise following several high-profile data leaks that have been extensively discussed in the media. For example, in April 2020 cyber criminals sold 267 million Facebook user profiles on the dark web for a bargain price of only US$540. Content on the dark web is arranged in a special way to provide anonymity to those who browse and share content. As such, you cannot access the dark web with a normal web browser. The most popular part of the dark web is called Tor. To access Tor, you need a special version of the Firefox browser. Tor, an acronym of The Onion Router, directs internet traffic through a worldwide volunteer network of relays and virtual tunnels (rather than the usual direct connections to internet sites)-each representing a layer of the onion. These relays allow users to conceal their location or usage from anyone conducting  network  surveillance  or  traffic analysis and are intended to protect the personal privacy of users. There are additional ways to further increase your anonymity on Tor by utilizing an operating system focused on security, such as the Linux-based operating systems Tails that was made famous by

This high level of privacy within Tor allows people to conduct a wide range of confidential activities. Some use it for sensitive communications, including political dissent. But in the past decade, it's also become a hub for illicit markets that sell or distribute weapons, drugs, stolen credit cards, illegal pornography, pirated media, and more. You can even hire assassins. It is important to note, however, that Tor was initially created by researchers supported by the U.S. government's Defense Advanced Research Projects Agency, or DARPA, as a tool for fostering democracy in repressive regimes. So, while the dark web has many nefarious uses, it also has great value in many parts of the world where free expression is outlawed.

Because of the noted difficulties in searching and accessing the massive dark web, very little has been done to make it more accessible to the general public. Given the  tremendous infrastructure resources required to search just the surface web, it is difficult to imagine the technologies, hardware, and software that would be required to allow the same search capabilities in the dark web. And given the nefarious nature of much of the dark web's content, perhaps society is better off making it difficult for most to navigate and utilize its content.

## Questions

- 3-49. What infrastructure components are most important for providing the surface web to the public users of the internet?
- 3-50. Should more effort be expended to enable wider access to the dark web? Why or why not?
- 3-51. What are the implications of the dark web for individuals? Companies? Governments?

Based on:

Dark web. (2020, July 14). In Wikipedia, The Free Encyclopedia . Retrieved July 16, 2020, from https://en.wikipedia.org/w/index.php?title=Dark\_ web&amp;oldid=967711716

## References

Amazon. (2020). Amazon Web Services. Amazon.com . Retrieved May 14, 2020, from http://aws.amazon.com

- CBInsights (2020, April 28). What is edge computing? CBInsights . Retrieved May 7, 2020, from https://www.cbinsights.com/ research/what-is-edge-computing

Constantinides, P., Henfridsson, O., &amp; Parker, G. (2018). Platforms and infrastructures in the digital age. Information Systems Research , 29 (2), 381-400.

DeMuro, J. (2019, December 18). What is private cloud? Techradar . Retrieved May 13, 2020, from https://www.techradar.com/news/ what-is-private-cloud

Evans, A., Martin, K., &amp; Poatsy, M.A. (2020). Technology in action complete (16th ed.). Boston, MA: Pearson.

- Finley, K. (2014, April 17). It's time to encrypt the entire internet. Wired. com . Retrieved May 13, 2020, from http://www.wired.com/2014/04/

Greenpeace (2017, January 10). Clicking clean. Retrieved May 13, 2020, from https://www.greenpeace.org/international/ publication/6826/clicking-clean-2017

Google. (2020). Google sustainability. Google.com . Retrieved May 13, 2020, from https://sustainability.google

Hiner, J. (2017, August 6). Public cloud, private cloud, or hybrid cloud: What's the difference? ZDNet.com . Retrieved May 13, 2020, from https://www.zdnet.com/article/public-cloud-privatecloud-or-hybrid-cloud-whats-the-difference

Hoffer, J., Ramesh, V., &amp; Topi, H. (2019). Modern database management (13th ed.). Boston, MA: Pearson.

Hofmann, P., &amp; Woods, D. (2010, November/December). Cloud computing: The limits of public clouds for business applications. IEEE internet Computing , 90-93.

Kreutzer, U. (2014, October 1). Defects: A vanishing species? Siemens.com . Retrieved April 18, 2016, from http://www.siemens .com/innovation/en/home/pictures-of-the-future/industry-andautomation/digital-factories-defects-a-vanishing-species.html

Kuross, K, &amp; Ross, J. (2021). Computer networking (8th ed.). Boston, MA: Pearson.

Doffman, Z. (2020, April 20). Facebook dark web deal: hackers just sold 267 million user profiles for $540. Forbes. Retrieved July 12, 2020, from https://www.forbes.com/sites/zakdoffman/2020/04/20/facebook-usersbeware-hackers-just-sold-267-million-of-your-profiles-for-540

Sheils, C. (2020, March 5). The deep web and the dark web. Digital.com. Retrieved July 12, 2020, from https://digital.com/online-privacy/deep-darkweb

Tor (anonymity network). (2020, July 13). In Wikipedia, The Free Encyclopedia . Retrieved July 16, 2020, from https://en.wikipedia.org/w/index .php?title=Tor\_anonymity\_network&amp;oldid=967437058

McKendrick, J. (2016, May 23). The new cloud computing economics: Too big to measure. Forbes . Retrieved May 13, 2020, from http://www.forbes.com/sites/joemckendrick/2016/05/23/thenew-cloud-computing-economics-too-big-to-measure

- Mell, P., &amp; Grance, T. (2011, September). The NIST definition of cloud computing. Retrieved May 13, 2020, from http://nvlpubs .nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-145.pdf

Netcraft. (220, April 8). April 2020 web server survey. Netcraft. com . Retrieved May 13, 2020, from https://news.netcraft.com/ archives/2020/04/08/april-2020-web-server-survey.html Panko, R., &amp; Panko, J. (2019).

Business data networks and security (11th ed.). Boston, MA: Pearson.

- Stallings, W. (2020). Cryptography and network security: Principles and practice (8th ed.). Boston, MA: Pearson.

Shaw, K. (2019, November 13). What is edge computing and why it matters. Networkworld . Retrieved May 7, 2020, from https:// www.networkworld.com/article/3224893/what-is-edgecomputing-and-how-it-s-changing-the-network.html

Top 500. (2019, November). Retrieved May 13, 2020, from http:// www.top500.org/lists/2019/11

Laudon, K.C., &amp; Traver, C. (2020). E-commerce 2019: Business, technology, society (15th ed.). Boston, MA: Pearson.

Ranger, S. (2018, December 13). What is cloud computing? Everything you need to know about the cloud, explained. ZDNet.com . Retrieved May 13, 2020, from https://www.zdnet.com/article/ what-is-cloud-computing-everything-you-need-to-know-frompublic-and-private-cloud-to-software-as-a

Valacich, J.S., &amp; George, J. F. (2020). Modern systems analysis and design (9th ed.). Boston, MA: Pearson.

Weinman, J. (2012). Cloudnomics: The business value of cloud computing . Hoboken, NJ: Wiley.

Weinman, J., (2015). Digital disciplines: Attaining market leadership via the cloud, Big Data, social, mobile, and the Internet of Things. Hoboken, NJ: Wiley.